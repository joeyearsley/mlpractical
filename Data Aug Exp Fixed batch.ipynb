{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Aug Experiments - Keep batch size the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.624. Accuracy is 8.60%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 3.053. Accuracy is 58.00%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.600. Accuracy is 81.41%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 8 seconds. Training speed 380 pps. Validation speed 1896 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.518. Accuracy is 83.50%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.497. Accuracy is 85.12%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 8 seconds. Training speed 460 pps. Validation speed 1819 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.324. Accuracy is 91.00%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.458. Accuracy is 85.38%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 8 seconds. Training speed 432 pps. Validation speed 1756 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.277. Accuracy is 92.10%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.389. Accuracy is 88.80%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 8 seconds. Training speed 462 pps. Validation speed 1795 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.171. Accuracy is 95.40%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.389. Accuracy is 89.03%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 8 seconds. Training speed 428 pps. Validation speed 1808 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.138. Accuracy is 96.90%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.376. Accuracy is 89.26%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 8 seconds. Training speed 375 pps. Validation speed 1772 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.098. Accuracy is 98.00%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.381. Accuracy is 89.46%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 9 seconds. Training speed 374 pps. Validation speed 1670 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.071. Accuracy is 99.00%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.379. Accuracy is 89.73%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 8 seconds. Training speed 431 pps. Validation speed 1856 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.056. Accuracy is 99.20%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.388. Accuracy is 89.77%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 8 seconds. Training speed 362 pps. Validation speed 1801 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.042. Accuracy is 99.40%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.388. Accuracy is 90.06%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 8 seconds. Training speed 378 pps. Validation speed 1787 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.033. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.429. Accuracy is 89.03%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 8 seconds. Training speed 369 pps. Validation speed 1813 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.029. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.403. Accuracy is 89.59%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 8 seconds. Training speed 379 pps. Validation speed 1836 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.022. Accuracy is 99.80%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.409. Accuracy is 89.73%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 8 seconds. Training speed 382 pps. Validation speed 1829 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.018. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.417. Accuracy is 89.73%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 8 seconds. Training speed 400 pps. Validation speed 1960 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.015. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.406. Accuracy is 90.08%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 8 seconds. Training speed 384 pps. Validation speed 1834 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.013. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.418. Accuracy is 89.95%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 8 seconds. Training speed 389 pps. Validation speed 1887 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.011. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.417. Accuracy is 90.03%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 8 seconds. Training speed 386 pps. Validation speed 1830 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.011. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.420. Accuracy is 90.10%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 8 seconds. Training speed 385 pps. Validation speed 1825 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.423. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 8 seconds. Training speed 393 pps. Validation speed 1830 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.425. Accuracy is 90.07%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 8 seconds. Training speed 387 pps. Validation speed 1837 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.429. Accuracy is 90.05%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 8 seconds. Training speed 410 pps. Validation speed 1868 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.429. Accuracy is 90.28%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 8 seconds. Training speed 386 pps. Validation speed 1839 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.430. Accuracy is 90.22%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 8 seconds. Training speed 387 pps. Validation speed 1849 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.433. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 8 seconds. Training speed 383 pps. Validation speed 1818 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.436. Accuracy is 90.35%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 8 seconds. Training speed 391 pps. Validation speed 1826 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.439. Accuracy is 90.23%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 8 seconds. Training speed 382 pps. Validation speed 1849 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.441. Accuracy is 90.28%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 8 seconds. Training speed 400 pps. Validation speed 1944 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.441. Accuracy is 90.32%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 8 seconds. Training speed 384 pps. Validation speed 1820 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.443. Accuracy is 90.29%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 8 seconds. Training speed 389 pps. Validation speed 1856 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.448. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 8 seconds. Training speed 386 pps. Validation speed 1824 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 89.44 %, cost (ce) is 0.457\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.377. Accuracy is 9.10%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.561. Accuracy is 9.00%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.334. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 7 seconds. Training speed 555 pps. Validation speed 1895 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.313. Accuracy is 10.50%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 2.310. Accuracy is 9.91%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 7 seconds. Training speed 558 pps. Validation speed 2011 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 2.313. Accuracy is 10.10%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 2.305. Accuracy is 10.30%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 7 seconds. Training speed 608 pps. Validation speed 1931 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 2.307. Accuracy is 10.60%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 2.315. Accuracy is 17.17%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 7 seconds. Training speed 587 pps. Validation speed 1872 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 2.297. Accuracy is 13.50%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 2.265. Accuracy is 25.55%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 7 seconds. Training speed 578 pps. Validation speed 1893 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 2.193. Accuracy is 18.50%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 2.118. Accuracy is 21.39%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 7 seconds. Training speed 562 pps. Validation speed 1872 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 1.887. Accuracy is 29.40%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 1.723. Accuracy is 31.62%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 7 seconds. Training speed 569 pps. Validation speed 1932 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 1.528. Accuracy is 41.30%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 1.209. Accuracy is 52.60%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 7 seconds. Training speed 581 pps. Validation speed 1930 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 1.114. Accuracy is 56.80%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.879. Accuracy is 66.98%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 7 seconds. Training speed 556 pps. Validation speed 2017 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.930. Accuracy is 65.80%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.763. Accuracy is 73.02%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 7 seconds. Training speed 585 pps. Validation speed 1916 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.767. Accuracy is 74.10%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.587. Accuracy is 81.62%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 7 seconds. Training speed 589 pps. Validation speed 1951 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.639. Accuracy is 78.90%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.790. Accuracy is 74.39%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 7 seconds. Training speed 579 pps. Validation speed 1930 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.545. Accuracy is 82.70%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.573. Accuracy is 82.08%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 7 seconds. Training speed 537 pps. Validation speed 1923 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.426. Accuracy is 85.50%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.583. Accuracy is 82.83%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 7 seconds. Training speed 573 pps. Validation speed 1911 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.400. Accuracy is 87.10%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.538. Accuracy is 84.21%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 7 seconds. Training speed 548 pps. Validation speed 1880 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.307. Accuracy is 90.70%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.886. Accuracy is 76.19%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 7 seconds. Training speed 553 pps. Validation speed 1980 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.303. Accuracy is 90.80%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.534. Accuracy is 84.39%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 7 seconds. Training speed 586 pps. Validation speed 1915 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.266. Accuracy is 91.10%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.501. Accuracy is 86.23%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 7 seconds. Training speed 534 pps. Validation speed 1917 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.157. Accuracy is 95.20%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.650. Accuracy is 83.20%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 7 seconds. Training speed 547 pps. Validation speed 1881 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.151. Accuracy is 95.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.508. Accuracy is 86.85%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 7 seconds. Training speed 560 pps. Validation speed 1922 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.120. Accuracy is 96.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.857. Accuracy is 80.50%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 7 seconds. Training speed 566 pps. Validation speed 1893 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.109. Accuracy is 96.70%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.505. Accuracy is 87.70%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 7 seconds. Training speed 575 pps. Validation speed 1882 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.087. Accuracy is 97.40%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.541. Accuracy is 87.34%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 7 seconds. Training speed 582 pps. Validation speed 1982 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.071. Accuracy is 98.10%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.654. Accuracy is 85.34%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 7 seconds. Training speed 566 pps. Validation speed 1966 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.071. Accuracy is 97.90%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.813. Accuracy is 82.50%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 7 seconds. Training speed 571 pps. Validation speed 1940 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.042. Accuracy is 99.30%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.562. Accuracy is 88.04%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 7 seconds. Training speed 560 pps. Validation speed 1938 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.035. Accuracy is 99.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.639. Accuracy is 86.33%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 7 seconds. Training speed 538 pps. Validation speed 1877 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.025. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.589. Accuracy is 87.69%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 7 seconds. Training speed 570 pps. Validation speed 1971 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.022. Accuracy is 99.60%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.600. Accuracy is 87.68%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 7 seconds. Training speed 576 pps. Validation speed 1891 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.020. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.602. Accuracy is 87.80%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 7 seconds. Training speed 552 pps. Validation speed 2012 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 87.70 %, cost (ce) is 0.597\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=10, max_num_batches=100, randomize=True, augmentation = 0)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['noAugF'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(2.5675238888641019, 0.083499999999999949), (3.2944894821772159, 0.48649999999999999), (0.82832050674946944, 0.72899999999999976), (0.59143224278500872, 0.81800000000000028), (0.51179130588525079, 0.83550000000000013), (0.37741398617988331, 0.88750000000000062), (0.33053541301047562, 0.8965000000000003), (0.28140210893374124, 0.91150000000000009), (0.22197073930798447, 0.9340000000000005), (0.16961350593641591, 0.96000000000000041), (0.15102098322278623, 0.96500000000000075), (0.11934304052474623, 0.97050000000000025), (0.10134453418312969, 0.98050000000000026), (0.086864214560214495, 0.98300000000000043), (0.071798417991226826, 0.99050000000000027), (0.058238673193779407, 0.99300000000000044), (0.055229166570296438, 0.99350000000000005), (0.046314642352540972, 0.99500000000000011), (0.040450229474914175, 0.99650000000000005), (0.034288786107912667, 0.99750000000000005), (0.030358601152831378, 0.99750000000000005), (0.027791666206491025, 0.998), (0.026170635255226674, 0.99750000000000016), (0.021564658858642675, 0.99950000000000006), (0.019872920515429923, 0.99900000000000011), (0.018664991463059274, 0.99900000000000011), (0.016681883236473832, 0.99950000000000006), (0.016262526771564395, 0.99950000000000006), (0.01447279642966285, 1.0), (0.01335772195875084, 1.0), (0.012406848238464295, 1.0)], [(2.5536554248681949, 0.090399999999999994), (0.93663087160487191, 0.70030000000000003), (0.82390597510053554, 0.7258), (0.73744459561043985, 0.76439999999999997), (0.5259932736780929, 0.84050000000000002), (0.49957243819818187, 0.85309999999999997), (0.48082220443742751, 0.84740000000000004), (0.48706360742309335, 0.85119999999999996), (0.43444407714913175, 0.87329999999999997), (0.45903866130448362, 0.86819999999999997), (0.42427224246326262, 0.87509999999999999), (0.46270102249574768, 0.86750000000000005), (0.41718979852802257, 0.88129999999999997), (0.41657997947104125, 0.88239999999999996), (0.42123080979435873, 0.88280000000000003), (0.40980001000546618, 0.88629999999999998), (0.42860151578718314, 0.88349999999999995), (0.41676764659659449, 0.88670000000000004), (0.42072631884880318, 0.88629999999999998), (0.41944925513364634, 0.89029999999999998), (0.41350387391145305, 0.89129999999999998), (0.41376583318875876, 0.89180000000000004), (0.42041397519666124, 0.8891), (0.41937956219354616, 0.89129999999999998), (0.41621614640179494, 0.8931), (0.41982229333097765, 0.89080000000000004), (0.42037310286275553, 0.89380000000000004), (0.42709638313807891, 0.89129999999999998), (0.41951528627292012, 0.89570000000000005), (0.42572767102255349, 0.89410000000000001), (0.43083354345833658, 0.89349999999999996)], (0.42694021157653023, 0.8881))\n"
     ]
    }
   ],
   "source": [
    "import shelve\n",
    "#Go through values array and put into new list.\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "print shelve_r['rotAugF0-8']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guassian augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.624. Accuracy is 8.60%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 3.053. Accuracy is 58.00%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.600. Accuracy is 81.41%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 8 seconds. Training speed 468 pps. Validation speed 1820 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.518. Accuracy is 83.50%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.497. Accuracy is 85.12%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 8 seconds. Training speed 370 pps. Validation speed 1843 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.324. Accuracy is 91.00%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.458. Accuracy is 85.38%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 8 seconds. Training speed 400 pps. Validation speed 1960 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.277. Accuracy is 92.10%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.389. Accuracy is 88.80%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 8 seconds. Training speed 402 pps. Validation speed 1808 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.171. Accuracy is 95.40%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.389. Accuracy is 89.03%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 8 seconds. Training speed 374 pps. Validation speed 1732 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.138. Accuracy is 96.90%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.376. Accuracy is 89.26%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 8 seconds. Training speed 392 pps. Validation speed 1844 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.098. Accuracy is 98.00%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.381. Accuracy is 89.46%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 8 seconds. Training speed 380 pps. Validation speed 1845 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.071. Accuracy is 99.00%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.379. Accuracy is 89.73%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 8 seconds. Training speed 389 pps. Validation speed 1822 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.056. Accuracy is 99.20%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.388. Accuracy is 89.77%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 8 seconds. Training speed 388 pps. Validation speed 1839 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.042. Accuracy is 99.40%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.388. Accuracy is 90.06%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 8 seconds. Training speed 420 pps. Validation speed 1816 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.033. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.429. Accuracy is 89.03%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 8 seconds. Training speed 385 pps. Validation speed 1875 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.029. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.403. Accuracy is 89.59%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 8 seconds. Training speed 389 pps. Validation speed 1830 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.022. Accuracy is 99.80%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.409. Accuracy is 89.73%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 8 seconds. Training speed 377 pps. Validation speed 1861 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.018. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.417. Accuracy is 89.73%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 8 seconds. Training speed 392 pps. Validation speed 1840 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.015. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.406. Accuracy is 90.08%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 8 seconds. Training speed 394 pps. Validation speed 1883 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.013. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.418. Accuracy is 89.95%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 8 seconds. Training speed 394 pps. Validation speed 1902 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.011. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.417. Accuracy is 90.03%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 8 seconds. Training speed 375 pps. Validation speed 1796 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.011. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.420. Accuracy is 90.10%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 8 seconds. Training speed 370 pps. Validation speed 1797 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.423. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 8 seconds. Training speed 365 pps. Validation speed 1817 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.425. Accuracy is 90.07%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 8 seconds. Training speed 373 pps. Validation speed 1798 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.429. Accuracy is 90.05%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 8 seconds. Training speed 397 pps. Validation speed 1827 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.429. Accuracy is 90.28%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 8 seconds. Training speed 372 pps. Validation speed 1952 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.430. Accuracy is 90.22%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 8 seconds. Training speed 385 pps. Validation speed 1727 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.433. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 8 seconds. Training speed 375 pps. Validation speed 1826 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.436. Accuracy is 90.35%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 8 seconds. Training speed 383 pps. Validation speed 1813 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.439. Accuracy is 90.23%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 8 seconds. Training speed 375 pps. Validation speed 1781 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.441. Accuracy is 90.28%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 8 seconds. Training speed 371 pps. Validation speed 1778 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.441. Accuracy is 90.32%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 8 seconds. Training speed 446 pps. Validation speed 1861 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.443. Accuracy is 90.29%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 8 seconds. Training speed 426 pps. Validation speed 1837 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.448. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 8 seconds. Training speed 382 pps. Validation speed 1819 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 89.44 %, cost (ce) is 0.457\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.377. Accuracy is 9.10%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.561. Accuracy is 9.00%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.334. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 8 seconds. Training speed 480 pps. Validation speed 1841 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.313. Accuracy is 10.50%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 2.310. Accuracy is 9.91%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 8 seconds. Training speed 500 pps. Validation speed 1815 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 2.313. Accuracy is 10.10%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 2.305. Accuracy is 10.30%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 7 seconds. Training speed 522 pps. Validation speed 1917 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 2.307. Accuracy is 10.60%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 2.315. Accuracy is 17.17%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 7 seconds. Training speed 631 pps. Validation speed 1854 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 2.297. Accuracy is 13.50%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 2.265. Accuracy is 25.55%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 7 seconds. Training speed 530 pps. Validation speed 1920 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 2.193. Accuracy is 18.50%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 2.118. Accuracy is 21.39%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 7 seconds. Training speed 533 pps. Validation speed 1907 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 1.887. Accuracy is 29.40%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 1.723. Accuracy is 31.62%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 7 seconds. Training speed 540 pps. Validation speed 1888 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 1.528. Accuracy is 41.30%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 1.209. Accuracy is 52.60%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 7 seconds. Training speed 572 pps. Validation speed 1884 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 1.114. Accuracy is 56.80%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.879. Accuracy is 66.98%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 8 seconds. Training speed 520 pps. Validation speed 1733 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.930. Accuracy is 65.80%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.763. Accuracy is 73.02%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 7 seconds. Training speed 505 pps. Validation speed 1856 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.767. Accuracy is 74.10%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.587. Accuracy is 81.62%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 7 seconds. Training speed 566 pps. Validation speed 1872 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.639. Accuracy is 78.90%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.790. Accuracy is 74.39%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 7 seconds. Training speed 573 pps. Validation speed 1944 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.545. Accuracy is 82.70%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.573. Accuracy is 82.08%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 7 seconds. Training speed 536 pps. Validation speed 1908 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.426. Accuracy is 85.50%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.583. Accuracy is 82.83%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 7 seconds. Training speed 526 pps. Validation speed 1868 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.400. Accuracy is 87.10%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.538. Accuracy is 84.21%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 7 seconds. Training speed 517 pps. Validation speed 1808 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.307. Accuracy is 90.70%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.886. Accuracy is 76.19%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 7 seconds. Training speed 514 pps. Validation speed 1811 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.303. Accuracy is 90.80%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.534. Accuracy is 84.39%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 7 seconds. Training speed 536 pps. Validation speed 1938 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.266. Accuracy is 91.10%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.501. Accuracy is 86.23%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 7 seconds. Training speed 541 pps. Validation speed 1871 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.157. Accuracy is 95.20%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.650. Accuracy is 83.20%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 7 seconds. Training speed 546 pps. Validation speed 1911 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.151. Accuracy is 95.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.508. Accuracy is 86.85%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 7 seconds. Training speed 549 pps. Validation speed 1865 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.120. Accuracy is 96.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.857. Accuracy is 80.50%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 7 seconds. Training speed 604 pps. Validation speed 1883 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.109. Accuracy is 96.70%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.505. Accuracy is 87.70%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 7 seconds. Training speed 541 pps. Validation speed 1814 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.087. Accuracy is 97.40%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.541. Accuracy is 87.34%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 7 seconds. Training speed 513 pps. Validation speed 1878 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.071. Accuracy is 98.10%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.654. Accuracy is 85.34%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 7 seconds. Training speed 537 pps. Validation speed 1974 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.071. Accuracy is 97.90%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.813. Accuracy is 82.50%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 7 seconds. Training speed 558 pps. Validation speed 1879 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.042. Accuracy is 99.30%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.562. Accuracy is 88.04%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 7 seconds. Training speed 549 pps. Validation speed 1924 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.035. Accuracy is 99.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.639. Accuracy is 86.33%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 7 seconds. Training speed 568 pps. Validation speed 1923 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.025. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.589. Accuracy is 87.69%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 7 seconds. Training speed 556 pps. Validation speed 1894 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.022. Accuracy is 99.60%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.600. Accuracy is 87.68%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 7 seconds. Training speed 518 pps. Validation speed 1881 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.020. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.602. Accuracy is 87.80%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 7 seconds. Training speed 530 pps. Validation speed 1906 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 87.70 %, cost (ce) is 0.597\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=10, max_num_batches=100, randomize=True, augmentation = 1)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['gauAugF'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotation Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.598. Accuracy is 8.90%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 3.215. Accuracy is 51.90%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.795. Accuracy is 74.86%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 9 seconds. Training speed 335 pps. Validation speed 1807 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.817. Accuracy is 73.25%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.650. Accuracy is 79.26%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 9 seconds. Training speed 315 pps. Validation speed 1748 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.617. Accuracy is 81.00%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.505. Accuracy is 84.57%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 8 seconds. Training speed 320 pps. Validation speed 1980 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.532. Accuracy is 82.20%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.471. Accuracy is 85.73%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 8 seconds. Training speed 333 pps. Validation speed 1830 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.426. Accuracy is 86.40%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.428. Accuracy is 87.41%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 9 seconds. Training speed 328 pps. Validation speed 1820 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.365. Accuracy is 88.30%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.461. Accuracy is 85.19%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 8 seconds. Training speed 357 pps. Validation speed 1833 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.350. Accuracy is 89.25%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.450. Accuracy is 86.81%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 8 seconds. Training speed 385 pps. Validation speed 1824 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.273. Accuracy is 92.25%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.398. Accuracy is 88.46%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 9 seconds. Training speed 297 pps. Validation speed 1786 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.248. Accuracy is 92.75%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.407. Accuracy is 88.12%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 9 seconds. Training speed 302 pps. Validation speed 1727 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.225. Accuracy is 93.90%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.407. Accuracy is 87.99%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 9 seconds. Training speed 311 pps. Validation speed 1804 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.184. Accuracy is 94.45%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.422. Accuracy is 88.18%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 9 seconds. Training speed 302 pps. Validation speed 1828 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.152. Accuracy is 95.80%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.383. Accuracy is 88.93%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 9 seconds. Training speed 318 pps. Validation speed 1818 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.157. Accuracy is 95.95%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.402. Accuracy is 88.97%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 9 seconds. Training speed 326 pps. Validation speed 1806 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.143. Accuracy is 96.50%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.378. Accuracy is 89.35%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 9 seconds. Training speed 325 pps. Validation speed 1841 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.119. Accuracy is 97.55%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.367. Accuracy is 89.79%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 9 seconds. Training speed 303 pps. Validation speed 1801 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.114. Accuracy is 97.20%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.412. Accuracy is 88.90%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 8 seconds. Training speed 375 pps. Validation speed 1856 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.093. Accuracy is 97.65%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.380. Accuracy is 89.57%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 9 seconds. Training speed 326 pps. Validation speed 1814 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.097. Accuracy is 97.55%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.366. Accuracy is 90.21%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 9 seconds. Training speed 325 pps. Validation speed 1842 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.082. Accuracy is 97.80%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.399. Accuracy is 89.53%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 9 seconds. Training speed 317 pps. Validation speed 1834 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.088. Accuracy is 97.70%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.370. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 9 seconds. Training speed 327 pps. Validation speed 1817 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.078. Accuracy is 98.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.371. Accuracy is 90.06%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 8 seconds. Training speed 370 pps. Validation speed 1764 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.073. Accuracy is 98.30%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.373. Accuracy is 90.25%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 9 seconds. Training speed 305 pps. Validation speed 1813 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.072. Accuracy is 98.55%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.371. Accuracy is 90.11%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 9 seconds. Training speed 308 pps. Validation speed 1820 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.067. Accuracy is 98.20%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.352. Accuracy is 90.80%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 9 seconds. Training speed 313 pps. Validation speed 1825 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.063. Accuracy is 98.30%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.367. Accuracy is 90.38%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 8 seconds. Training speed 321 pps. Validation speed 1874 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.060. Accuracy is 98.50%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.388. Accuracy is 89.89%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 9 seconds. Training speed 310 pps. Validation speed 1854 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.046. Accuracy is 98.75%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.368. Accuracy is 90.28%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 9 seconds. Training speed 334 pps. Validation speed 1809 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.049. Accuracy is 99.05%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.373. Accuracy is 90.47%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 9 seconds. Training speed 318 pps. Validation speed 1840 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.044. Accuracy is 99.10%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.384. Accuracy is 90.21%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 9 seconds. Training speed 325 pps. Validation speed 1760 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.034. Accuracy is 99.35%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.378. Accuracy is 90.49%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 9 seconds. Training speed 315 pps. Validation speed 1823 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 90.04 %, cost (ce) is 0.378\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.377. Accuracy is 9.10%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.561. Accuracy is 9.05%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.334. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 7 seconds. Training speed 459 pps. Validation speed 1889 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.314. Accuracy is 10.25%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 2.311. Accuracy is 9.91%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 8 seconds. Training speed 448 pps. Validation speed 1729 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 2.315. Accuracy is 9.85%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 2.307. Accuracy is 10.30%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 8 seconds. Training speed 460 pps. Validation speed 1808 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 2.310. Accuracy is 9.75%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 2.318. Accuracy is 18.18%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 8 seconds. Training speed 425 pps. Validation speed 1864 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 2.308. Accuracy is 10.45%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 2.298. Accuracy is 17.72%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 7 seconds. Training speed 470 pps. Validation speed 1933 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 2.304. Accuracy is 12.00%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 2.292. Accuracy is 12.97%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 7 seconds. Training speed 455 pps. Validation speed 1921 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 2.244. Accuracy is 18.25%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 2.110. Accuracy is 22.19%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 7 seconds. Training speed 457 pps. Validation speed 1987 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 2.015. Accuracy is 25.40%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 1.772. Accuracy is 32.48%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 7 seconds. Training speed 455 pps. Validation speed 1897 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 1.790. Accuracy is 34.45%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 1.601. Accuracy is 38.84%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 7 seconds. Training speed 475 pps. Validation speed 1896 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 1.500. Accuracy is 44.90%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 1.100. Accuracy is 55.60%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 7 seconds. Training speed 485 pps. Validation speed 1908 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 1.206. Accuracy is 58.30%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.907. Accuracy is 68.97%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 7 seconds. Training speed 462 pps. Validation speed 1891 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 1.047. Accuracy is 62.95%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.940. Accuracy is 69.70%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 7 seconds. Training speed 474 pps. Validation speed 1894 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.936. Accuracy is 67.10%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.718. Accuracy is 77.15%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 7 seconds. Training speed 464 pps. Validation speed 1971 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.819. Accuracy is 72.30%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.669. Accuracy is 79.20%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 7 seconds. Training speed 464 pps. Validation speed 1908 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.761. Accuracy is 75.20%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.631. Accuracy is 80.06%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 7 seconds. Training speed 454 pps. Validation speed 1896 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.696. Accuracy is 77.60%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.604. Accuracy is 80.77%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 7 seconds. Training speed 477 pps. Validation speed 1858 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.658. Accuracy is 78.75%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.631. Accuracy is 78.78%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 7 seconds. Training speed 457 pps. Validation speed 1912 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.617. Accuracy is 81.10%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.602. Accuracy is 81.29%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 7 seconds. Training speed 460 pps. Validation speed 1948 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.550. Accuracy is 81.45%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.643. Accuracy is 78.08%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 7 seconds. Training speed 469 pps. Validation speed 1956 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.499. Accuracy is 83.50%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.549. Accuracy is 81.79%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 7 seconds. Training speed 489 pps. Validation speed 1946 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.473. Accuracy is 84.35%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.712. Accuracy is 78.87%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 7 seconds. Training speed 470 pps. Validation speed 1947 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.437. Accuracy is 86.45%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.463. Accuracy is 85.63%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 7 seconds. Training speed 450 pps. Validation speed 1913 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.420. Accuracy is 86.50%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.461. Accuracy is 85.91%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 7 seconds. Training speed 465 pps. Validation speed 1917 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.366. Accuracy is 87.75%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.472. Accuracy is 86.01%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 8 seconds. Training speed 462 pps. Validation speed 1872 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.359. Accuracy is 88.85%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.766. Accuracy is 78.14%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 8 seconds. Training speed 454 pps. Validation speed 1879 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.329. Accuracy is 89.05%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.539. Accuracy is 84.62%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 7 seconds. Training speed 474 pps. Validation speed 2000 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.305. Accuracy is 90.10%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.484. Accuracy is 85.86%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 7 seconds. Training speed 467 pps. Validation speed 1927 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.250. Accuracy is 92.50%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.489. Accuracy is 86.20%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 7 seconds. Training speed 481 pps. Validation speed 1915 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.266. Accuracy is 91.50%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.487. Accuracy is 85.95%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 7 seconds. Training speed 461 pps. Validation speed 1904 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.234. Accuracy is 93.30%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.500. Accuracy is 86.07%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 7 seconds. Training speed 464 pps. Validation speed 1875 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 85.07 %, cost (ce) is 0.529\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=10, max_num_batches=100, randomize=True, augmentation = 2)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['rotAugF'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.624. Accuracy is 8.60%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.851. Accuracy is 61.50%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.594. Accuracy is 81.14%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 8 seconds. Training speed 389 pps. Validation speed 1870 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.502. Accuracy is 84.10%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.460. Accuracy is 86.49%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 8 seconds. Training speed 373 pps. Validation speed 1825 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.334. Accuracy is 89.50%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.666. Accuracy is 80.03%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 8 seconds. Training speed 382 pps. Validation speed 1840 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.259. Accuracy is 92.30%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.432. Accuracy is 87.61%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 8 seconds. Training speed 373 pps. Validation speed 1870 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.188. Accuracy is 94.80%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.396. Accuracy is 88.48%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 8 seconds. Training speed 375 pps. Validation speed 1826 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.129. Accuracy is 97.20%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.409. Accuracy is 88.38%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 8 seconds. Training speed 417 pps. Validation speed 1812 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.090. Accuracy is 98.40%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.379. Accuracy is 89.74%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 8 seconds. Training speed 376 pps. Validation speed 1844 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.072. Accuracy is 98.80%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.386. Accuracy is 89.87%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 8 seconds. Training speed 382 pps. Validation speed 1842 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.054. Accuracy is 99.50%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.400. Accuracy is 89.56%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 8 seconds. Training speed 376 pps. Validation speed 1817 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.042. Accuracy is 99.30%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.396. Accuracy is 89.89%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 8 seconds. Training speed 377 pps. Validation speed 1845 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.032. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.431. Accuracy is 88.88%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 8 seconds. Training speed 372 pps. Validation speed 1845 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.024. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.408. Accuracy is 89.64%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 8 seconds. Training speed 381 pps. Validation speed 1876 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.020. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.420. Accuracy is 89.82%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 8 seconds. Training speed 387 pps. Validation speed 1860 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.017. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.420. Accuracy is 89.93%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 8 seconds. Training speed 374 pps. Validation speed 1866 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.014. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.432. Accuracy is 89.69%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 8 seconds. Training speed 381 pps. Validation speed 1804 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.013. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.430. Accuracy is 89.79%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 8 seconds. Training speed 381 pps. Validation speed 1856 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.011. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.424. Accuracy is 90.21%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 8 seconds. Training speed 383 pps. Validation speed 1861 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.010. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.429. Accuracy is 90.18%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 8 seconds. Training speed 377 pps. Validation speed 1957 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.439. Accuracy is 89.85%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 8 seconds. Training speed 444 pps. Validation speed 1890 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.437. Accuracy is 90.12%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 8 seconds. Training speed 387 pps. Validation speed 1817 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.441. Accuracy is 90.01%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 8 seconds. Training speed 377 pps. Validation speed 1836 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.445. Accuracy is 89.89%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 8 seconds. Training speed 379 pps. Validation speed 1783 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.445. Accuracy is 90.09%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 8 seconds. Training speed 368 pps. Validation speed 1821 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.449. Accuracy is 89.97%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 8 seconds. Training speed 382 pps. Validation speed 1831 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.450. Accuracy is 90.08%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 8 seconds. Training speed 406 pps. Validation speed 1865 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.449. Accuracy is 90.03%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 8 seconds. Training speed 380 pps. Validation speed 1807 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.453. Accuracy is 90.14%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 8 seconds. Training speed 388 pps. Validation speed 1819 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.455. Accuracy is 89.96%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 8 seconds. Training speed 379 pps. Validation speed 1834 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.460. Accuracy is 89.91%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 8 seconds. Training speed 367 pps. Validation speed 1814 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.456. Accuracy is 90.20%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 8 seconds. Training speed 375 pps. Validation speed 1866 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 89.44 %, cost (ce) is 0.464\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.377. Accuracy is 9.10%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.541. Accuracy is 11.60%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.308. Accuracy is 10.64%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 7 seconds. Training speed 524 pps. Validation speed 1815 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.315. Accuracy is 10.10%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 2.305. Accuracy is 10.30%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 7 seconds. Training speed 532 pps. Validation speed 1864 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 2.311. Accuracy is 10.00%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 2.308. Accuracy is 10.64%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 8 seconds. Training speed 483 pps. Validation speed 1789 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 2.303. Accuracy is 12.50%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 2.291. Accuracy is 9.61%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 8 seconds. Training speed 485 pps. Validation speed 1699 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 2.257. Accuracy is 15.00%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 2.193. Accuracy is 16.83%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 8 seconds. Training speed 491 pps. Validation speed 1746 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 1.996. Accuracy is 27.50%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 1.790. Accuracy is 35.07%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 7 seconds. Training speed 512 pps. Validation speed 1966 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 1.588. Accuracy is 40.90%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 1.147. Accuracy is 60.39%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 7 seconds. Training speed 547 pps. Validation speed 1864 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 1.119. Accuracy is 58.80%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.923. Accuracy is 67.37%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 8 seconds. Training speed 532 pps. Validation speed 1766 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.978. Accuracy is 64.40%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 1.011. Accuracy is 64.44%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 7 seconds. Training speed 507 pps. Validation speed 1873 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.801. Accuracy is 70.60%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.881. Accuracy is 66.00%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 7 seconds. Training speed 522 pps. Validation speed 1862 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.656. Accuracy is 77.60%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.632. Accuracy is 79.76%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 7 seconds. Training speed 513 pps. Validation speed 1811 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.516. Accuracy is 83.70%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.520. Accuracy is 84.20%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 8 seconds. Training speed 537 pps. Validation speed 1582 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.472. Accuracy is 84.30%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.563. Accuracy is 82.03%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 8 seconds. Training speed 503 pps. Validation speed 1643 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.424. Accuracy is 86.50%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.657. Accuracy is 79.18%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 8 seconds. Training speed 460 pps. Validation speed 1603 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.364. Accuracy is 88.00%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.571. Accuracy is 83.29%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 8 seconds. Training speed 501 pps. Validation speed 1665 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.294. Accuracy is 90.60%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.807. Accuracy is 76.96%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 8 seconds. Training speed 521 pps. Validation speed 1595 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.231. Accuracy is 93.70%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.494. Accuracy is 86.31%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 8 seconds. Training speed 463 pps. Validation speed 1613 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.225. Accuracy is 92.60%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.590. Accuracy is 84.32%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 9 seconds. Training speed 447 pps. Validation speed 1594 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.183. Accuracy is 94.70%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.910. Accuracy is 77.83%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 8 seconds. Training speed 444 pps. Validation speed 1634 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.178. Accuracy is 95.30%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.630. Accuracy is 84.52%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 8 seconds. Training speed 460 pps. Validation speed 1585 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.114. Accuracy is 96.70%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.503. Accuracy is 87.16%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 8 seconds. Training speed 462 pps. Validation speed 1599 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.097. Accuracy is 97.10%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.517. Accuracy is 87.97%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 9 seconds. Training speed 454 pps. Validation speed 1580 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.079. Accuracy is 97.90%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.633. Accuracy is 85.89%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 9 seconds. Training speed 448 pps. Validation speed 1591 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.064. Accuracy is 98.40%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.579. Accuracy is 87.66%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 8 seconds. Training speed 463 pps. Validation speed 1584 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.062. Accuracy is 98.30%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.574. Accuracy is 87.99%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 9 seconds. Training speed 463 pps. Validation speed 1572 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.034. Accuracy is 99.40%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.604. Accuracy is 87.42%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 8 seconds. Training speed 498 pps. Validation speed 1593 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.042. Accuracy is 99.20%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.562. Accuracy is 88.19%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 8 seconds. Training speed 463 pps. Validation speed 1607 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.022. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.569. Accuracy is 88.05%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 9 seconds. Training speed 460 pps. Validation speed 1573 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.023. Accuracy is 99.60%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.581. Accuracy is 88.27%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 9 seconds. Training speed 436 pps. Validation speed 1531 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.016. Accuracy is 99.60%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.597. Accuracy is 87.91%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 9 seconds. Training speed 443 pps. Validation speed 1575 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 87.83 %, cost (ce) is 0.595\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=10, max_num_batches=100, randomize=True, augmentation = 3)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['dpAugF'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Shift Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.624. Accuracy is 7.50%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 3.589. Accuracy is 43.60%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.895. Accuracy is 71.53%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 9 seconds. Training speed 385 pps. Validation speed 1525 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.988. Accuracy is 69.05%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.573. Accuracy is 83.65%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 10 seconds. Training speed 325 pps. Validation speed 1525 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.770. Accuracy is 75.90%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.669. Accuracy is 79.51%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 9 seconds. Training speed 394 pps. Validation speed 1575 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.706. Accuracy is 77.80%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.516. Accuracy is 85.01%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 9 seconds. Training speed 335 pps. Validation speed 1600 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.545. Accuracy is 84.05%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.421. Accuracy is 88.24%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 9 seconds. Training speed 394 pps. Validation speed 1567 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.495. Accuracy is 84.40%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.420. Accuracy is 87.43%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 9 seconds. Training speed 337 pps. Validation speed 1563 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.439. Accuracy is 87.10%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.429. Accuracy is 87.25%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 10 seconds. Training speed 324 pps. Validation speed 1550 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.378. Accuracy is 89.30%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.364. Accuracy is 89.83%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 10 seconds. Training speed 321 pps. Validation speed 1547 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.309. Accuracy is 90.90%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.368. Accuracy is 90.07%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 10 seconds. Training speed 336 pps. Validation speed 1519 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.319. Accuracy is 91.45%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.385. Accuracy is 88.90%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 10 seconds. Training speed 319 pps. Validation speed 1546 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.277. Accuracy is 91.95%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.379. Accuracy is 89.51%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 9 seconds. Training speed 405 pps. Validation speed 1594 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.243. Accuracy is 93.40%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.374. Accuracy is 88.77%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 9 seconds. Training speed 401 pps. Validation speed 1584 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.218. Accuracy is 94.10%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.353. Accuracy is 90.18%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 10 seconds. Training speed 321 pps. Validation speed 1495 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.211. Accuracy is 93.95%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.321. Accuracy is 91.28%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 9 seconds. Training speed 384 pps. Validation speed 1561 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.204. Accuracy is 94.40%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.319. Accuracy is 91.21%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 9 seconds. Training speed 334 pps. Validation speed 1636 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.188. Accuracy is 95.20%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.406. Accuracy is 88.44%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 9 seconds. Training speed 349 pps. Validation speed 1521 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.185. Accuracy is 95.00%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.301. Accuracy is 91.80%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 10 seconds. Training speed 322 pps. Validation speed 1533 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.143. Accuracy is 95.90%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.300. Accuracy is 91.82%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 9 seconds. Training speed 384 pps. Validation speed 1506 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.146. Accuracy is 96.20%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.329. Accuracy is 91.06%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 9 seconds. Training speed 339 pps. Validation speed 1544 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.148. Accuracy is 96.25%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.307. Accuracy is 91.63%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 9 seconds. Training speed 343 pps. Validation speed 1538 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.137. Accuracy is 96.40%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.295. Accuracy is 91.89%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 9 seconds. Training speed 392 pps. Validation speed 1604 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.128. Accuracy is 96.75%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.292. Accuracy is 92.13%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 9 seconds. Training speed 401 pps. Validation speed 1593 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.106. Accuracy is 96.95%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.298. Accuracy is 91.90%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 8 seconds. Training speed 429 pps. Validation speed 1634 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.114. Accuracy is 97.20%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.283. Accuracy is 92.58%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 9 seconds. Training speed 343 pps. Validation speed 1585 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.108. Accuracy is 97.50%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.288. Accuracy is 92.18%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 9 seconds. Training speed 395 pps. Validation speed 1569 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.094. Accuracy is 97.90%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.315. Accuracy is 91.43%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 9 seconds. Training speed 400 pps. Validation speed 1585 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.095. Accuracy is 97.75%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.296. Accuracy is 92.23%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 9 seconds. Training speed 441 pps. Validation speed 1559 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.092. Accuracy is 97.10%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.296. Accuracy is 92.12%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 9 seconds. Training speed 336 pps. Validation speed 1593 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.082. Accuracy is 97.85%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.299. Accuracy is 92.16%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 10 seconds. Training speed 323 pps. Validation speed 1503 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.083. Accuracy is 97.95%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.291. Accuracy is 92.33%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 9 seconds. Training speed 350 pps. Validation speed 1640 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 92.15 %, cost (ce) is 0.292\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.376. Accuracy is 9.10%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.562. Accuracy is 9.05%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.334. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 9 seconds. Training speed 431 pps. Validation speed 1532 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.315. Accuracy is 10.10%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 2.311. Accuracy is 9.91%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 9 seconds. Training speed 436 pps. Validation speed 1576 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 2.315. Accuracy is 9.70%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 2.307. Accuracy is 10.30%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 9 seconds. Training speed 486 pps. Validation speed 1518 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 2.311. Accuracy is 9.45%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 2.319. Accuracy is 18.64%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 8 seconds. Training speed 468 pps. Validation speed 1609 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 2.311. Accuracy is 9.95%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 2.302. Accuracy is 18.68%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 8 seconds. Training speed 509 pps. Validation speed 1626 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 2.312. Accuracy is 11.20%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 2.309. Accuracy is 9.90%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 8 seconds. Training speed 494 pps. Validation speed 1675 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 2.303. Accuracy is 12.45%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 2.334. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 8 seconds. Training speed 498 pps. Validation speed 1615 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 2.255. Accuracy is 15.15%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 2.088. Accuracy is 29.84%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 8 seconds. Training speed 518 pps. Validation speed 1634 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 2.105. Accuracy is 20.75%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 2.115. Accuracy is 15.61%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 8 seconds. Training speed 516 pps. Validation speed 1621 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 1.943. Accuracy is 25.65%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 1.674. Accuracy is 38.89%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 8 seconds. Training speed 518 pps. Validation speed 1649 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 1.699. Accuracy is 37.15%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 1.356. Accuracy is 47.25%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 8 seconds. Training speed 460 pps. Validation speed 1611 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 1.468. Accuracy is 48.85%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 1.144. Accuracy is 55.25%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 8 seconds. Training speed 462 pps. Validation speed 1596 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 1.272. Accuracy is 56.35%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.911. Accuracy is 69.72%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 8 seconds. Training speed 471 pps. Validation speed 1627 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 1.141. Accuracy is 60.00%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.886. Accuracy is 70.39%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 8 seconds. Training speed 474 pps. Validation speed 1599 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 1.084. Accuracy is 61.45%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.842. Accuracy is 71.77%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 8 seconds. Training speed 463 pps. Validation speed 1599 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.941. Accuracy is 67.65%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.746. Accuracy is 73.88%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 8 seconds. Training speed 469 pps. Validation speed 1645 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.882. Accuracy is 69.90%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.941. Accuracy is 67.24%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 8 seconds. Training speed 534 pps. Validation speed 1604 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.875. Accuracy is 69.00%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.728. Accuracy is 76.01%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 8 seconds. Training speed 473 pps. Validation speed 1608 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.816. Accuracy is 72.75%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.762. Accuracy is 73.61%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 8 seconds. Training speed 474 pps. Validation speed 1602 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.736. Accuracy is 75.90%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.586. Accuracy is 81.37%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 8 seconds. Training speed 460 pps. Validation speed 1587 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.673. Accuracy is 77.20%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.618. Accuracy is 80.14%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 8 seconds. Training speed 477 pps. Validation speed 1608 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.636. Accuracy is 78.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.538. Accuracy is 83.04%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 8 seconds. Training speed 494 pps. Validation speed 1590 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.632. Accuracy is 79.40%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.528. Accuracy is 83.21%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 8 seconds. Training speed 468 pps. Validation speed 1652 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.554. Accuracy is 82.85%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.494. Accuracy is 85.15%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 8 seconds. Training speed 479 pps. Validation speed 1601 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.509. Accuracy is 83.55%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.612. Accuracy is 82.31%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 8 seconds. Training speed 469 pps. Validation speed 1614 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.493. Accuracy is 84.80%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.560. Accuracy is 83.93%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 8 seconds. Training speed 488 pps. Validation speed 1619 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.499. Accuracy is 84.15%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.485. Accuracy is 85.58%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 8 seconds. Training speed 465 pps. Validation speed 1621 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.467. Accuracy is 85.55%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.397. Accuracy is 88.55%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 8 seconds. Training speed 475 pps. Validation speed 1602 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.395. Accuracy is 87.75%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.393. Accuracy is 88.42%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 8 seconds. Training speed 476 pps. Validation speed 1597 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.356. Accuracy is 88.90%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.453. Accuracy is 87.10%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 8 seconds. Training speed 537 pps. Validation speed 1635 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 86.67 %, cost (ce) is 0.481\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=10, max_num_batches=100, randomize=True, augmentation = 4)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['siAugF'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.621. Accuracy is 8.20%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 3.020. Accuracy is 53.10%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.629. Accuracy is 79.91%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 9 seconds. Training speed 345 pps. Validation speed 1603 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.759. Accuracy is 76.70%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.566. Accuracy is 82.65%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 9 seconds. Training speed 326 pps. Validation speed 1590 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.627. Accuracy is 81.25%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.511. Accuracy is 84.96%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 9 seconds. Training speed 317 pps. Validation speed 1651 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.566. Accuracy is 83.90%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.429. Accuracy is 87.49%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 9 seconds. Training speed 335 pps. Validation speed 1541 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.424. Accuracy is 86.90%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.392. Accuracy is 88.09%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 9 seconds. Training speed 317 pps. Validation speed 1595 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.386. Accuracy is 89.95%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.358. Accuracy is 89.54%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 9 seconds. Training speed 321 pps. Validation speed 1597 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.315. Accuracy is 91.55%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.387. Accuracy is 88.77%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 9 seconds. Training speed 324 pps. Validation speed 1563 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.283. Accuracy is 92.45%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.364. Accuracy is 89.46%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 9 seconds. Training speed 341 pps. Validation speed 1593 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.262. Accuracy is 93.90%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.390. Accuracy is 88.84%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 9 seconds. Training speed 326 pps. Validation speed 1603 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.244. Accuracy is 94.35%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.344. Accuracy is 90.20%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 9 seconds. Training speed 356 pps. Validation speed 1589 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.246. Accuracy is 93.35%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.350. Accuracy is 90.14%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 9 seconds. Training speed 318 pps. Validation speed 1626 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.226. Accuracy is 94.55%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.363. Accuracy is 89.88%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 9 seconds. Training speed 322 pps. Validation speed 1586 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.197. Accuracy is 95.05%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.400. Accuracy is 88.48%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 9 seconds. Training speed 321 pps. Validation speed 1595 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.180. Accuracy is 96.20%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.316. Accuracy is 90.84%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 9 seconds. Training speed 324 pps. Validation speed 1586 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.165. Accuracy is 95.90%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.333. Accuracy is 90.75%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 9 seconds. Training speed 330 pps. Validation speed 1571 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.161. Accuracy is 96.15%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.338. Accuracy is 90.43%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 9 seconds. Training speed 329 pps. Validation speed 1591 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.167. Accuracy is 96.20%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.323. Accuracy is 90.96%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 9 seconds. Training speed 376 pps. Validation speed 1584 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.153. Accuracy is 96.05%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.321. Accuracy is 91.06%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 9 seconds. Training speed 323 pps. Validation speed 1586 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.127. Accuracy is 96.85%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.343. Accuracy is 90.69%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 9 seconds. Training speed 350 pps. Validation speed 1581 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.113. Accuracy is 97.30%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.315. Accuracy is 91.12%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 9 seconds. Training speed 325 pps. Validation speed 1593 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.131. Accuracy is 96.70%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.331. Accuracy is 90.83%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 9 seconds. Training speed 317 pps. Validation speed 1583 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.122. Accuracy is 97.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.306. Accuracy is 91.68%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 9 seconds. Training speed 318 pps. Validation speed 1670 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.112. Accuracy is 96.85%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.306. Accuracy is 91.77%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 9 seconds. Training speed 325 pps. Validation speed 1575 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.112. Accuracy is 97.10%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.297. Accuracy is 91.82%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 9 seconds. Training speed 321 pps. Validation speed 1594 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.100. Accuracy is 97.55%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.331. Accuracy is 90.38%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 9 seconds. Training speed 374 pps. Validation speed 1585 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.086. Accuracy is 97.85%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.296. Accuracy is 91.67%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 9 seconds. Training speed 376 pps. Validation speed 1585 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.099. Accuracy is 97.20%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.299. Accuracy is 91.78%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 9 seconds. Training speed 321 pps. Validation speed 1607 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.085. Accuracy is 97.80%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.309. Accuracy is 91.53%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 9 seconds. Training speed 374 pps. Validation speed 1664 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.099. Accuracy is 97.75%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.286. Accuracy is 92.00%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 9 seconds. Training speed 339 pps. Validation speed 1596 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.079. Accuracy is 98.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.307. Accuracy is 91.68%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 9 seconds. Training speed 354 pps. Validation speed 1624 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 91.12 %, cost (ce) is 0.309\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.377. Accuracy is 9.10%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.558. Accuracy is 9.35%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.320. Accuracy is 10.64%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 8 seconds. Training speed 456 pps. Validation speed 1618 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.317. Accuracy is 11.05%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 2.323. Accuracy is 10.87%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 9 seconds. Training speed 452 pps. Validation speed 1577 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 2.313. Accuracy is 10.45%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 2.306. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 8 seconds. Training speed 427 pps. Validation speed 1645 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 2.307. Accuracy is 11.95%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 2.296. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 8 seconds. Training speed 479 pps. Validation speed 1589 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 2.291. Accuracy is 15.05%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 2.262. Accuracy is 11.70%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 8 seconds. Training speed 451 pps. Validation speed 1615 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 2.213. Accuracy is 19.75%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 2.051. Accuracy is 31.14%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 9 seconds. Training speed 437 pps. Validation speed 1611 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 2.003. Accuracy is 27.40%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 1.839. Accuracy is 35.54%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 9 seconds. Training speed 434 pps. Validation speed 1589 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 1.757. Accuracy is 38.05%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 1.398. Accuracy is 49.89%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 9 seconds. Training speed 428 pps. Validation speed 1589 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 1.426. Accuracy is 50.10%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 1.071. Accuracy is 64.08%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 8 seconds. Training speed 472 pps. Validation speed 1601 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 1.176. Accuracy is 57.85%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.914. Accuracy is 69.67%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 8 seconds. Training speed 470 pps. Validation speed 1614 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 1.052. Accuracy is 63.50%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.926. Accuracy is 66.67%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 8 seconds. Training speed 439 pps. Validation speed 1643 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.908. Accuracy is 69.00%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.824. Accuracy is 71.37%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 8 seconds. Training speed 448 pps. Validation speed 1605 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.855. Accuracy is 72.65%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.688. Accuracy is 78.40%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 8 seconds. Training speed 514 pps. Validation speed 1619 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.771. Accuracy is 75.15%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.717. Accuracy is 75.58%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 8 seconds. Training speed 444 pps. Validation speed 1608 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.657. Accuracy is 79.40%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.504. Accuracy is 84.65%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 9 seconds. Training speed 433 pps. Validation speed 1615 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.630. Accuracy is 79.90%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.539. Accuracy is 82.31%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 8 seconds. Training speed 443 pps. Validation speed 1633 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.553. Accuracy is 82.40%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.495. Accuracy is 84.58%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 8 seconds. Training speed 564 pps. Validation speed 1600 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.536. Accuracy is 81.85%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.573. Accuracy is 81.64%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 8 seconds. Training speed 443 pps. Validation speed 1615 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.472. Accuracy is 85.80%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.449. Accuracy is 86.24%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 9 seconds. Training speed 438 pps. Validation speed 1599 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.434. Accuracy is 87.15%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.465. Accuracy is 85.88%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 8 seconds. Training speed 456 pps. Validation speed 1613 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.380. Accuracy is 88.80%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.448. Accuracy is 86.58%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 8 seconds. Training speed 536 pps. Validation speed 1589 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.388. Accuracy is 88.25%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.606. Accuracy is 82.02%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 9 seconds. Training speed 444 pps. Validation speed 1599 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.355. Accuracy is 89.70%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.437. Accuracy is 87.04%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 8 seconds. Training speed 442 pps. Validation speed 1641 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.294. Accuracy is 92.00%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.476. Accuracy is 85.75%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 8 seconds. Training speed 452 pps. Validation speed 1656 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.291. Accuracy is 91.40%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.410. Accuracy is 88.22%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 8 seconds. Training speed 469 pps. Validation speed 1575 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.284. Accuracy is 92.20%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.484. Accuracy is 85.66%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 9 seconds. Training speed 431 pps. Validation speed 1603 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.309. Accuracy is 91.20%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.417. Accuracy is 87.60%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 8 seconds. Training speed 441 pps. Validation speed 1633 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.254. Accuracy is 92.45%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.384. Accuracy is 88.84%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 8 seconds. Training speed 435 pps. Validation speed 1632 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.239. Accuracy is 92.60%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.363. Accuracy is 89.24%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 8 seconds. Training speed 453 pps. Validation speed 1605 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.228. Accuracy is 93.65%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.451. Accuracy is 86.93%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 8 seconds. Training speed 473 pps. Validation speed 1628 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 86.46 %, cost (ce) is 0.468\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=10, max_num_batches=100, randomize=True, augmentation = 5)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['ranAugF'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
