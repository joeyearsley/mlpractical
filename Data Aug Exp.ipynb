{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Aug Experiments - Mention increase in batch size to 500, as one will inflate batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.570. Accuracy is 9.32%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 0.805. Accuracy is 85.26%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.337. Accuracy is 89.83%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 39 seconds. Training speed 752 pps. Validation speed 1643 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.277. Accuracy is 91.73%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.239. Accuracy is 92.90%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 40 seconds. Training speed 748 pps. Validation speed 1601 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.222. Accuracy is 93.52%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.202. Accuracy is 94.34%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 39 seconds. Training speed 763 pps. Validation speed 1547 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.183. Accuracy is 94.58%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.172. Accuracy is 95.24%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 40 seconds. Training speed 737 pps. Validation speed 1580 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.156. Accuracy is 95.38%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.171. Accuracy is 95.46%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 41 seconds. Training speed 735 pps. Validation speed 1488 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.133. Accuracy is 96.15%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.142. Accuracy is 96.15%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 40 seconds. Training speed 732 pps. Validation speed 1700 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.116. Accuracy is 96.66%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.146. Accuracy is 95.83%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 41 seconds. Training speed 726 pps. Validation speed 1550 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.101. Accuracy is 97.08%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.124. Accuracy is 96.61%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 40 seconds. Training speed 739 pps. Validation speed 1600 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.089. Accuracy is 97.42%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.121. Accuracy is 96.81%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 41 seconds. Training speed 726 pps. Validation speed 1593 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.080. Accuracy is 97.77%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.117. Accuracy is 96.69%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 41 seconds. Training speed 732 pps. Validation speed 1572 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.070. Accuracy is 98.10%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.114. Accuracy is 96.86%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 40 seconds. Training speed 739 pps. Validation speed 1630 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.062. Accuracy is 98.32%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.112. Accuracy is 96.84%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 39 seconds. Training speed 757 pps. Validation speed 1623 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.056. Accuracy is 98.53%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.105. Accuracy is 97.01%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 39 seconds. Training speed 751 pps. Validation speed 1626 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.050. Accuracy is 98.74%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.102. Accuracy is 97.16%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 41 seconds. Training speed 732 pps. Validation speed 1571 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.045. Accuracy is 98.91%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.105. Accuracy is 97.04%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 38 seconds. Training speed 778 pps. Validation speed 1606 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.041. Accuracy is 99.02%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.102. Accuracy is 97.20%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 38 seconds. Training speed 797 pps. Validation speed 1600 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.036. Accuracy is 99.17%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.099. Accuracy is 97.33%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 39 seconds. Training speed 769 pps. Validation speed 1587 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.032. Accuracy is 99.30%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.097. Accuracy is 97.27%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 38 seconds. Training speed 776 pps. Validation speed 1607 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.030. Accuracy is 99.41%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.095. Accuracy is 97.26%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 39 seconds. Training speed 766 pps. Validation speed 1553 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.027. Accuracy is 99.55%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.096. Accuracy is 97.48%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 38 seconds. Training speed 775 pps. Validation speed 1648 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.024. Accuracy is 99.58%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.096. Accuracy is 97.44%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 39 seconds. Training speed 761 pps. Validation speed 1666 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.022. Accuracy is 99.64%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.095. Accuracy is 97.43%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 38 seconds. Training speed 780 pps. Validation speed 1557 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.020. Accuracy is 99.72%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.097. Accuracy is 97.26%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 39 seconds. Training speed 771 pps. Validation speed 1581 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.018. Accuracy is 99.78%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.095. Accuracy is 97.36%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 39 seconds. Training speed 758 pps. Validation speed 1546 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.017. Accuracy is 99.78%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.097. Accuracy is 97.30%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 39 seconds. Training speed 772 pps. Validation speed 1571 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.016. Accuracy is 99.85%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.098. Accuracy is 97.43%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 39 seconds. Training speed 767 pps. Validation speed 1560 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.014. Accuracy is 99.87%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.097. Accuracy is 97.41%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 38 seconds. Training speed 782 pps. Validation speed 1595 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.013. Accuracy is 99.91%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.096. Accuracy is 97.35%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 39 seconds. Training speed 760 pps. Validation speed 1680 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.012. Accuracy is 99.91%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.095. Accuracy is 97.49%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 39 seconds. Training speed 761 pps. Validation speed 1618 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.011. Accuracy is 99.94%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.098. Accuracy is 97.38%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 39 seconds. Training speed 764 pps. Validation speed 1638 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 97.40 %, cost (ce) is 0.092\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.376. Accuracy is 9.91%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 1.951. Accuracy is 28.43%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.820. Accuracy is 72.89%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 35 seconds. Training speed 868 pps. Validation speed 1588 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.558. Accuracy is 81.94%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.357. Accuracy is 89.10%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 36 seconds. Training speed 852 pps. Validation speed 1603 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.349. Accuracy is 89.35%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.305. Accuracy is 90.43%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 35 seconds. Training speed 867 pps. Validation speed 1627 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.279. Accuracy is 91.32%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.245. Accuracy is 92.45%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 35 seconds. Training speed 853 pps. Validation speed 1771 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.229. Accuracy is 93.06%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.201. Accuracy is 94.00%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 35 seconds. Training speed 865 pps. Validation speed 1641 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.196. Accuracy is 94.02%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.171. Accuracy is 94.94%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 35 seconds. Training speed 868 pps. Validation speed 1621 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.167. Accuracy is 94.79%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.164. Accuracy is 95.17%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 36 seconds. Training speed 855 pps. Validation speed 1598 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.148. Accuracy is 95.42%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.161. Accuracy is 95.39%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 32 seconds. Training speed 917 pps. Validation speed 1980 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.130. Accuracy is 96.08%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.140. Accuracy is 95.90%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 31 seconds. Training speed 960 pps. Validation speed 1912 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.115. Accuracy is 96.53%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.171. Accuracy is 94.99%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 32 seconds. Training speed 925 pps. Validation speed 1861 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.101. Accuracy is 96.87%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.143. Accuracy is 95.78%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 33 seconds. Training speed 918 pps. Validation speed 1734 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.090. Accuracy is 97.26%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.156. Accuracy is 95.33%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 33 seconds. Training speed 908 pps. Validation speed 1877 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.078. Accuracy is 97.60%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.126. Accuracy is 96.40%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 32 seconds. Training speed 938 pps. Validation speed 1892 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.071. Accuracy is 97.82%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.158. Accuracy is 95.79%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 33 seconds. Training speed 903 pps. Validation speed 1782 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.062. Accuracy is 98.18%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.128. Accuracy is 96.51%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 33 seconds. Training speed 920 pps. Validation speed 1825 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.056. Accuracy is 98.18%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.122. Accuracy is 96.72%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 33 seconds. Training speed 921 pps. Validation speed 1665 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.051. Accuracy is 98.40%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.125. Accuracy is 96.62%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 33 seconds. Training speed 910 pps. Validation speed 1883 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.046. Accuracy is 98.54%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.108. Accuracy is 97.11%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 33 seconds. Training speed 909 pps. Validation speed 1890 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.040. Accuracy is 98.82%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.115. Accuracy is 96.98%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 33 seconds. Training speed 911 pps. Validation speed 1961 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.035. Accuracy is 99.05%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.114. Accuracy is 96.99%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 32 seconds. Training speed 926 pps. Validation speed 1854 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.028. Accuracy is 99.24%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.131. Accuracy is 96.49%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 33 seconds. Training speed 896 pps. Validation speed 1836 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.027. Accuracy is 99.24%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.117. Accuracy is 96.99%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 32 seconds. Training speed 929 pps. Validation speed 1934 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.030. Accuracy is 99.15%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.130. Accuracy is 96.85%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 33 seconds. Training speed 918 pps. Validation speed 1842 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.021. Accuracy is 99.43%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.121. Accuracy is 96.89%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 33 seconds. Training speed 920 pps. Validation speed 1810 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.014. Accuracy is 99.66%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.136. Accuracy is 96.68%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 33 seconds. Training speed 890 pps. Validation speed 1868 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.012. Accuracy is 99.68%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.119. Accuracy is 97.34%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 32 seconds. Training speed 940 pps. Validation speed 1866 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.010. Accuracy is 99.77%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.136. Accuracy is 97.04%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 34 seconds. Training speed 891 pps. Validation speed 1827 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.007. Accuracy is 99.88%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.126. Accuracy is 97.16%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 32 seconds. Training speed 928 pps. Validation speed 1827 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.006. Accuracy is 99.88%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.126. Accuracy is 97.32%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 33 seconds. Training speed 895 pps. Validation speed 1874 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.006. Accuracy is 99.87%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.127. Accuracy is 97.18%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 33 seconds. Training speed 917 pps. Validation speed 1887 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 97.13 %, cost (ce) is 0.120\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=50, max_num_batches=500, randomize=True, augmentation = 0)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['noAug'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(2.5703508233660521, 0.093239999999999837), (0.80523317568429009, 0.85255999999999876), (0.27677549487643593, 0.91727999999999832), (0.22214730183563638, 0.93519999999999825), (0.18305137563708659, 0.94583999999999857), (0.15569982539570845, 0.95375999999999872), (0.13300080456875954, 0.9615199999999996), (0.11569182332048453, 0.96659999999999957), (0.10137976111233382, 0.9708), (0.088637899782371021, 0.97419999999999984), (0.079508461866036467, 0.97772000000000003), (0.070032142996076019, 0.98096000000000105), (0.062405188919370608, 0.9832000000000013), (0.055755217898011723, 0.98532000000000119), (0.04967158365777917, 0.98744000000000121), (0.04458790914267511, 0.98912000000000144), (0.040571948966103173, 0.99020000000000119), (0.036383325059962189, 0.99172000000000138), (0.032378143263541291, 0.99300000000000133), (0.029633980765690616, 0.9940800000000013), (0.026752833110905212, 0.99552000000000074), (0.024419206568088901, 0.9958000000000008), (0.022283936445299839, 0.99644000000000099), (0.020426003503800961, 0.99720000000000075), (0.018373570548880142, 0.99776000000000065), (0.017081363931949669, 0.99776000000000076), (0.015679766499505924, 0.99852000000000074), (0.014156501216024237, 0.99868000000000001), (0.013498181197960828, 0.99908000000000063), (0.012289599282016629, 0.99912000000000056), (0.011351036727095292, 0.99936000000000014)], [(2.5535497258761009, 0.098400000000000001), (0.33671330578696718, 0.89829999999999999), (0.23891238190127584, 0.92900000000000005), (0.20236318925468633, 0.94340000000000002), (0.17230566591938834, 0.95240000000000002), (0.17095267353612659, 0.9546), (0.1422519712481129, 0.96150000000000002), (0.14553004047410278, 0.95830000000000004), (0.12432306946479585, 0.96609999999999996), (0.12125752531609912, 0.96809999999999996), (0.11700666866391364, 0.96689999999999998), (0.1141506231164771, 0.96860000000000002), (0.11161868278035454, 0.96840000000000004), (0.10505397281456885, 0.97009999999999996), (0.10204037316560445, 0.97160000000000002), (0.10487224348522473, 0.97040000000000004), (0.10182463345379623, 0.97199999999999998), (0.098589431970232941, 0.97330000000000005), (0.09665586316200929, 0.97270000000000001), (0.095186040241131267, 0.97260000000000002), (0.096356009879375093, 0.9748), (0.096063583129408839, 0.97440000000000004), (0.094546509742299445, 0.97430000000000005), (0.097064316785876792, 0.97260000000000002), (0.095231162429616989, 0.97360000000000002), (0.09701217357475346, 0.97299999999999998), (0.098328930756980043, 0.97430000000000005), (0.096675300312268023, 0.97409999999999997), (0.096110424882530784, 0.97350000000000003), (0.094810086611919961, 0.97489999999999999), (0.097963335103077448, 0.9738)], (0.091880895620131325, 0.97399999999999998))\n"
     ]
    }
   ],
   "source": [
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "print shelve_r['noAug0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guassian augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.579. Accuracy is 9.04%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 1.301. Accuracy is 78.70%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.435. Accuracy is 86.18%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 17 seconds. Training speed 597 pps. Validation speed 1609 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.340. Accuracy is 89.79%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.328. Accuracy is 90.27%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 17 seconds. Training speed 583 pps. Validation speed 1536 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.273. Accuracy is 91.78%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.304. Accuracy is 91.06%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 17 seconds. Training speed 580 pps. Validation speed 1585 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.224. Accuracy is 93.12%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.277. Accuracy is 92.18%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 17 seconds. Training speed 580 pps. Validation speed 1609 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.190. Accuracy is 94.21%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.258. Accuracy is 92.48%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 17 seconds. Training speed 606 pps. Validation speed 1575 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.158. Accuracy is 95.26%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.239. Accuracy is 93.18%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 17 seconds. Training speed 589 pps. Validation speed 1545 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.136. Accuracy is 95.97%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.229. Accuracy is 93.43%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 17 seconds. Training speed 595 pps. Validation speed 1613 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.114. Accuracy is 96.86%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.211. Accuracy is 94.05%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 17 seconds. Training speed 590 pps. Validation speed 1608 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.095. Accuracy is 97.55%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.212. Accuracy is 94.22%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 17 seconds. Training speed 589 pps. Validation speed 1581 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.083. Accuracy is 97.86%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.217. Accuracy is 93.88%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 17 seconds. Training speed 590 pps. Validation speed 1580 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.069. Accuracy is 98.26%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.206. Accuracy is 94.37%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 17 seconds. Training speed 582 pps. Validation speed 1627 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.059. Accuracy is 98.62%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.218. Accuracy is 93.92%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 17 seconds. Training speed 589 pps. Validation speed 1511 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.050. Accuracy is 99.09%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.197. Accuracy is 94.61%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 17 seconds. Training speed 587 pps. Validation speed 1554 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.042. Accuracy is 99.18%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.208. Accuracy is 93.96%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 17 seconds. Training speed 589 pps. Validation speed 1574 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.036. Accuracy is 99.47%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.208. Accuracy is 94.13%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 17 seconds. Training speed 595 pps. Validation speed 1584 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.031. Accuracy is 99.63%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.220. Accuracy is 93.58%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 17 seconds. Training speed 582 pps. Validation speed 1593 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.027. Accuracy is 99.74%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.198. Accuracy is 94.82%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 17 seconds. Training speed 580 pps. Validation speed 1521 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.023. Accuracy is 99.76%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.211. Accuracy is 94.39%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 17 seconds. Training speed 604 pps. Validation speed 1544 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.020. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.204. Accuracy is 94.52%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 18 seconds. Training speed 563 pps. Validation speed 1497 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.018. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.194. Accuracy is 95.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 18 seconds. Training speed 569 pps. Validation speed 1520 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.016. Accuracy is 99.97%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.196. Accuracy is 94.97%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 17 seconds. Training speed 582 pps. Validation speed 1548 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.014. Accuracy is 99.98%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.203. Accuracy is 94.82%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 17 seconds. Training speed 599 pps. Validation speed 1548 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.013. Accuracy is 99.97%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.198. Accuracy is 94.97%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 18 seconds. Training speed 569 pps. Validation speed 1523 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.012. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.201. Accuracy is 94.93%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 18 seconds. Training speed 568 pps. Validation speed 1471 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.011. Accuracy is 99.98%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.200. Accuracy is 94.87%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 18 seconds. Training speed 576 pps. Validation speed 1457 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.010. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.200. Accuracy is 94.98%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 18 seconds. Training speed 577 pps. Validation speed 1483 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.199. Accuracy is 95.02%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 18 seconds. Training speed 562 pps. Validation speed 1477 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.009. Accuracy is 99.97%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.202. Accuracy is 95.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 18 seconds. Training speed 560 pps. Validation speed 1431 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.201. Accuracy is 95.07%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 18 seconds. Training speed 561 pps. Validation speed 1467 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.008. Accuracy is 99.98%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.201. Accuracy is 95.15%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 18 seconds. Training speed 565 pps. Validation speed 1485 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 94.83 %, cost (ce) is 0.201\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.379. Accuracy is 9.71%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.375. Accuracy is 11.15%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.232. Accuracy is 18.30%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 17 seconds. Training speed 611 pps. Validation speed 1586 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 1.641. Accuracy is 38.70%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.809. Accuracy is 72.66%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 16 seconds. Training speed 641 pps. Validation speed 1528 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.756. Accuracy is 74.13%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.521. Accuracy is 82.29%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 17 seconds. Training speed 627 pps. Validation speed 1473 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.478. Accuracy is 84.61%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.424. Accuracy is 86.72%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 17 seconds. Training speed 638 pps. Validation speed 1488 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.398. Accuracy is 87.44%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.337. Accuracy is 89.65%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 17 seconds. Training speed 637 pps. Validation speed 1473 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.335. Accuracy is 89.23%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.294. Accuracy is 90.79%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 17 seconds. Training speed 619 pps. Validation speed 1426 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.290. Accuracy is 90.56%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.345. Accuracy is 89.25%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 17 seconds. Training speed 615 pps. Validation speed 1471 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.247. Accuracy is 92.27%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.251. Accuracy is 92.47%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 17 seconds. Training speed 620 pps. Validation speed 1481 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.214. Accuracy is 93.20%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.254. Accuracy is 92.58%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 17 seconds. Training speed 612 pps. Validation speed 1442 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.190. Accuracy is 94.00%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.238. Accuracy is 93.09%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 17 seconds. Training speed 611 pps. Validation speed 1431 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.168. Accuracy is 94.74%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.251. Accuracy is 93.04%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 17 seconds. Training speed 616 pps. Validation speed 1503 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.141. Accuracy is 95.87%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.266. Accuracy is 92.39%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 17 seconds. Training speed 621 pps. Validation speed 1473 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.125. Accuracy is 96.21%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.235. Accuracy is 93.23%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 17 seconds. Training speed 629 pps. Validation speed 1436 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.107. Accuracy is 96.62%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.212. Accuracy is 93.91%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 17 seconds. Training speed 613 pps. Validation speed 1442 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.100. Accuracy is 97.02%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.226. Accuracy is 93.68%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 17 seconds. Training speed 618 pps. Validation speed 1463 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.083. Accuracy is 97.38%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.215. Accuracy is 94.20%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 17 seconds. Training speed 637 pps. Validation speed 1477 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.068. Accuracy is 97.82%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.224. Accuracy is 93.90%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 17 seconds. Training speed 627 pps. Validation speed 1422 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.060. Accuracy is 98.06%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.226. Accuracy is 94.20%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 17 seconds. Training speed 615 pps. Validation speed 1438 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.053. Accuracy is 98.37%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.343. Accuracy is 91.60%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 17 seconds. Training speed 614 pps. Validation speed 1477 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.041. Accuracy is 98.75%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.240. Accuracy is 94.14%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 17 seconds. Training speed 632 pps. Validation speed 1465 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.037. Accuracy is 98.98%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.272. Accuracy is 93.57%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 17 seconds. Training speed 642 pps. Validation speed 1478 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.028. Accuracy is 99.20%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.245. Accuracy is 94.38%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 17 seconds. Training speed 616 pps. Validation speed 1450 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.021. Accuracy is 99.47%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.259. Accuracy is 93.96%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 17 seconds. Training speed 615 pps. Validation speed 1426 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.018. Accuracy is 99.57%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.233. Accuracy is 94.69%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 17 seconds. Training speed 633 pps. Validation speed 1457 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.015. Accuracy is 99.68%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.231. Accuracy is 94.85%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 17 seconds. Training speed 626 pps. Validation speed 1467 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.008. Accuracy is 99.84%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.240. Accuracy is 94.79%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 17 seconds. Training speed 616 pps. Validation speed 1465 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.006. Accuracy is 99.89%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.236. Accuracy is 94.93%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 17 seconds. Training speed 617 pps. Validation speed 1434 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.004. Accuracy is 99.97%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.243. Accuracy is 94.95%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 17 seconds. Training speed 623 pps. Validation speed 1458 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.003. Accuracy is 99.98%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.247. Accuracy is 94.77%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 17 seconds. Training speed 617 pps. Validation speed 1460 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.003. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.245. Accuracy is 95.03%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 17 seconds. Training speed 618 pps. Validation speed 1484 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 94.63 %, cost (ce) is 0.242\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=25, max_num_batches=250, randomize=True, augmentation = 1)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"gauAugExperimentsExp\", writeback = True)\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['gauAug'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(2.3790590745646081, 0.097119999999999762), (2.3748161530123317, 0.11151999999999983), (1.6409201908863589, 0.38703999999999994), (0.7558383033078464, 0.74127999999999949), (0.47846208888599773, 0.84608000000000005), (0.39780283055768723, 0.8743999999999994), (0.33509262225273961, 0.89231999999999878), (0.29037617268422339, 0.90559999999999918), (0.2472264746783514, 0.92271999999999921), (0.21449407290921876, 0.93199999999999883), (0.19019722626937655, 0.93999999999999873), (0.16791916829606451, 0.94735999999999954), (0.14123214584240851, 0.95871999999999968), (0.12549076818379581, 0.96207999999999982), (0.10716737740252844, 0.96623999999999988), (0.099828401529748478, 0.97023999999999977), (0.083076926009576238, 0.97376000000000018), (0.067910550623422827, 0.97823999999999967), (0.060152025862470426, 0.98063999999999996), (0.052654247122175514, 0.98368000000000022), (0.041009519504898853, 0.98751999999999984), (0.037014065078455928, 0.98975999999999997), (0.028081005832056458, 0.99200000000000055), (0.020647528570458786, 0.99472000000000027), (0.018315320999032093, 0.99568000000000045), (0.014693590003619972, 0.99680000000000013), (0.0082763748518975225, 0.99840000000000007), (0.0063370882957805427, 0.99887999999999977), (0.0044272729527844133, 0.99968000000000001), (0.0034428142003094853, 0.99984000000000006), (0.0027372043783964995, 1.0)], [(2.3795721363921292, 0.1009), (2.2324180218871859, 0.183), (0.80899839504922133, 0.72660000000000002), (0.52109989786516886, 0.82289999999999996), (0.42433474556118517, 0.86719999999999997), (0.33660615674538846, 0.89649999999999996), (0.29423831905474063, 0.90790000000000004), (0.34450788558011108, 0.89249999999999996), (0.2509114563089142, 0.92469999999999997), (0.25352526505185302, 0.92579999999999996), (0.2381220986845739, 0.93089999999999995), (0.25059766742632383, 0.9304), (0.26555153258891318, 0.92390000000000005), (0.23500805801644323, 0.93230000000000002), (0.21243186265013819, 0.93910000000000005), (0.22607505819512708, 0.93679999999999997), (0.21453618082048462, 0.94199999999999995), (0.22437849408017524, 0.93899999999999995), (0.22562426129848837, 0.94199999999999995), (0.34266767293326061, 0.91600000000000004), (0.24039177246483179, 0.94140000000000001), (0.27208262956330387, 0.93569999999999998), (0.24452545812546705, 0.94379999999999997), (0.25900065846925263, 0.93959999999999999), (0.23325772048254004, 0.94689999999999996), (0.23102944743416862, 0.94850000000000001), (0.23959804811803814, 0.94789999999999996), (0.2357456209922576, 0.94930000000000003), (0.24265542004096755, 0.94950000000000001), (0.24665187303846309, 0.94769999999999999), (0.24533850125990939, 0.95030000000000003)], (0.24210700606837118, 0.94630000000000003))\n"
     ]
    }
   ],
   "source": [
    "shelve_r = shelve.open(\"gauAugExperimentsExp\")\n",
    "\n",
    "print shelve_r['gauAug1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotation Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.556. Accuracy is 9.29%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 1.546. Accuracy is 70.56%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.531. Accuracy is 83.27%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 17 seconds. Training speed 528 pps. Validation speed 1839 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.522. Accuracy is 83.85%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.385. Accuracy is 88.80%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 18 seconds. Training speed 507 pps. Validation speed 1859 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.426. Accuracy is 87.08%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.328. Accuracy is 90.77%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 18 seconds. Training speed 516 pps. Validation speed 1692 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.353. Accuracy is 89.58%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.288. Accuracy is 91.76%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 18 seconds. Training speed 520 pps. Validation speed 1727 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.294. Accuracy is 91.42%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.268. Accuracy is 92.01%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 18 seconds. Training speed 513 pps. Validation speed 1690 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.251. Accuracy is 92.51%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.232. Accuracy is 93.48%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 17 seconds. Training speed 529 pps. Validation speed 1856 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.222. Accuracy is 93.33%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.224. Accuracy is 93.36%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 17 seconds. Training speed 526 pps. Validation speed 1800 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.199. Accuracy is 94.42%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.199. Accuracy is 94.25%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 17 seconds. Training speed 530 pps. Validation speed 1849 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.171. Accuracy is 94.99%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.214. Accuracy is 94.05%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 17 seconds. Training speed 544 pps. Validation speed 1835 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.157. Accuracy is 95.62%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.195. Accuracy is 94.46%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 18 seconds. Training speed 518 pps. Validation speed 1733 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.141. Accuracy is 96.01%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.185. Accuracy is 94.88%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 17 seconds. Training speed 516 pps. Validation speed 1894 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.128. Accuracy is 96.42%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.190. Accuracy is 94.35%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 18 seconds. Training speed 511 pps. Validation speed 1754 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.120. Accuracy is 96.70%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.162. Accuracy is 95.26%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 17 seconds. Training speed 523 pps. Validation speed 1818 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.111. Accuracy is 97.13%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.177. Accuracy is 94.71%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 18 seconds. Training speed 512 pps. Validation speed 1811 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.098. Accuracy is 97.31%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.173. Accuracy is 94.90%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 17 seconds. Training speed 548 pps. Validation speed 1851 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.090. Accuracy is 97.66%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.171. Accuracy is 94.70%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 17 seconds. Training speed 547 pps. Validation speed 1852 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.085. Accuracy is 97.66%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.162. Accuracy is 95.23%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 17 seconds. Training speed 555 pps. Validation speed 1848 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.081. Accuracy is 97.90%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.162. Accuracy is 95.23%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 17 seconds. Training speed 553 pps. Validation speed 1848 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.074. Accuracy is 98.17%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.162. Accuracy is 95.26%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 17 seconds. Training speed 555 pps. Validation speed 1838 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.069. Accuracy is 98.22%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.145. Accuracy is 96.01%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 17 seconds. Training speed 558 pps. Validation speed 1857 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.066. Accuracy is 98.38%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.147. Accuracy is 95.97%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 17 seconds. Training speed 550 pps. Validation speed 1840 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.063. Accuracy is 98.45%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.150. Accuracy is 95.69%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 17 seconds. Training speed 552 pps. Validation speed 1853 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.057. Accuracy is 98.71%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.146. Accuracy is 95.76%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 17 seconds. Training speed 563 pps. Validation speed 1826 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.058. Accuracy is 98.48%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.147. Accuracy is 95.91%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 17 seconds. Training speed 537 pps. Validation speed 1866 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.055. Accuracy is 98.65%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.142. Accuracy is 96.15%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 17 seconds. Training speed 548 pps. Validation speed 1866 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.047. Accuracy is 98.88%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.142. Accuracy is 96.05%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 17 seconds. Training speed 560 pps. Validation speed 1831 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.048. Accuracy is 98.83%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.141. Accuracy is 95.89%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 17 seconds. Training speed 546 pps. Validation speed 1851 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.044. Accuracy is 99.03%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.141. Accuracy is 96.05%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 17 seconds. Training speed 554 pps. Validation speed 1871 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.043. Accuracy is 99.02%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.144. Accuracy is 96.05%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 16 seconds. Training speed 566 pps. Validation speed 1871 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.039. Accuracy is 99.10%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.143. Accuracy is 96.15%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 17 seconds. Training speed 549 pps. Validation speed 1797 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 95.99 %, cost (ce) is 0.137\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.379. Accuracy is 9.71%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.381. Accuracy is 10.49%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.287. Accuracy is 9.83%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 15 seconds. Training speed 624 pps. Validation speed 1901 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.068. Accuracy is 23.06%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 1.410. Accuracy is 46.56%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 15 seconds. Training speed 625 pps. Validation speed 1908 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 1.152. Accuracy is 59.01%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.784. Accuracy is 71.64%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 15 seconds. Training speed 623 pps. Validation speed 1894 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.755. Accuracy is 75.10%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.505. Accuracy is 84.25%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 15 seconds. Training speed 634 pps. Validation speed 1817 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.615. Accuracy is 80.38%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.458. Accuracy is 85.46%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 15 seconds. Training speed 619 pps. Validation speed 1922 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.519. Accuracy is 83.53%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.378. Accuracy is 88.33%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 16 seconds. Training speed 609 pps. Validation speed 1905 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.460. Accuracy is 85.30%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.382. Accuracy is 87.81%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 15 seconds. Training speed 635 pps. Validation speed 1916 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.410. Accuracy is 86.93%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.302. Accuracy is 90.32%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 16 seconds. Training speed 586 pps. Validation speed 1808 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.357. Accuracy is 88.44%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.335. Accuracy is 89.56%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 17 seconds. Training speed 559 pps. Validation speed 1843 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.325. Accuracy is 89.54%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.243. Accuracy is 92.51%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 16 seconds. Training speed 593 pps. Validation speed 1827 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.289. Accuracy is 91.01%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.270. Accuracy is 92.07%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 16 seconds. Training speed 583 pps. Validation speed 1900 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.260. Accuracy is 91.65%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.279. Accuracy is 91.58%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 16 seconds. Training speed 587 pps. Validation speed 1912 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.232. Accuracy is 92.53%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.220. Accuracy is 93.13%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 15 seconds. Training speed 641 pps. Validation speed 1902 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.210. Accuracy is 93.50%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.253. Accuracy is 92.13%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 16 seconds. Training speed 601 pps. Validation speed 1924 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.188. Accuracy is 93.97%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.252. Accuracy is 92.33%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 15 seconds. Training speed 622 pps. Validation speed 1924 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.185. Accuracy is 94.18%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.209. Accuracy is 93.56%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 15 seconds. Training speed 626 pps. Validation speed 1940 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.154. Accuracy is 95.11%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.181. Accuracy is 94.61%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 16 seconds. Training speed 611 pps. Validation speed 1822 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.146. Accuracy is 95.08%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.207. Accuracy is 93.58%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 16 seconds. Training speed 593 pps. Validation speed 1853 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.134. Accuracy is 95.70%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.256. Accuracy is 92.29%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 15 seconds. Training speed 632 pps. Validation speed 1916 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.125. Accuracy is 95.81%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.201. Accuracy is 94.18%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 15 seconds. Training speed 609 pps. Validation speed 1928 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.122. Accuracy is 96.32%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.189. Accuracy is 94.54%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 16 seconds. Training speed 612 pps. Validation speed 1871 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.106. Accuracy is 96.59%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.179. Accuracy is 94.75%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 16 seconds. Training speed 605 pps. Validation speed 1872 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.091. Accuracy is 97.26%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.186. Accuracy is 94.77%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 16 seconds. Training speed 586 pps. Validation speed 1885 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.096. Accuracy is 97.10%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.208. Accuracy is 93.90%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 15 seconds. Training speed 611 pps. Validation speed 1908 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.092. Accuracy is 97.02%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.186. Accuracy is 94.87%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 15 seconds. Training speed 628 pps. Validation speed 1882 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.075. Accuracy is 97.66%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.176. Accuracy is 95.15%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 15 seconds. Training speed 617 pps. Validation speed 1885 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.072. Accuracy is 97.74%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.191. Accuracy is 94.88%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 16 seconds. Training speed 579 pps. Validation speed 1826 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.080. Accuracy is 97.47%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.168. Accuracy is 95.39%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 15 seconds. Training speed 625 pps. Validation speed 1890 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.065. Accuracy is 98.05%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.180. Accuracy is 95.12%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 15 seconds. Training speed 619 pps. Validation speed 1885 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.070. Accuracy is 97.84%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.166. Accuracy is 95.61%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 15 seconds. Training speed 619 pps. Validation speed 1933 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 95.48 %, cost (ce) is 0.164\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=25, max_num_batches=250, randomize=True, augmentation = 2)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['rotAug'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(2.5562683854356489, 0.092879999999999921), (1.5462982589063765, 0.70559999999999989), (0.52189560304094995, 0.83848000000000067), (0.42601826261832176, 0.87079999999999957), (0.35337329232518222, 0.89584000000000008), (0.29377871768666169, 0.91415999999999931), (0.25147616865457145, 0.92511999999999917), (0.22159527630811471, 0.93327999999999944), (0.19857560650501502, 0.94423999999999864), (0.17065748879635703, 0.94991999999999932), (0.15739096503117883, 0.95615999999999868), (0.14088532762064696, 0.96007999999999927), (0.12800619988959416, 0.96423999999999932), (0.12028947523356515, 0.96695999999999938), (0.11102779961198238, 0.97127999999999903), (0.098303455248003366, 0.97311999999999876), (0.090107473644583214, 0.97663999999999851), (0.085240087924978794, 0.9765599999999991), (0.081285213966619668, 0.97903999999999891), (0.073936646915694307, 0.98167999999999878), (0.068661238422579068, 0.98223999999999922), (0.065987430741484179, 0.98383999999999849), (0.062576911035505542, 0.98447999999999836), (0.057157856532776434, 0.98711999999999878), (0.05836131241731192, 0.98479999999999834), (0.054861843143869965, 0.98647999999999847), (0.047313922558208675, 0.98879999999999912), (0.048282828617332518, 0.98831999999999864), (0.043959980024938103, 0.99031999999999909), (0.042513829937615939, 0.99015999999999904), (0.038962053094678914, 0.9910399999999987)], [(2.5535497258761009, 0.098400000000000001), (0.53095794079653513, 0.8327), (0.3847975785344892, 0.88800000000000001), (0.32811904856890112, 0.90769999999999995), (0.28833518032017907, 0.91759999999999997), (0.26849039268389641, 0.92010000000000003), (0.23190436179304252, 0.93479999999999996), (0.22357345145821295, 0.93359999999999999), (0.1988263761413088, 0.9425), (0.21354910981776962, 0.9405), (0.19521755192628301, 0.9446), (0.18535467485224727, 0.94879999999999998), (0.18957229794384883, 0.94350000000000001), (0.16209442276715202, 0.9526), (0.17689308919717014, 0.94710000000000005), (0.17309306076018746, 0.94899999999999995), (0.17128083105509678, 0.94699999999999995), (0.1616393732473787, 0.95230000000000004), (0.16191196993569271, 0.95230000000000004), (0.16190569925171841, 0.9526), (0.14470813146043601, 0.96009999999999995), (0.14665529683316686, 0.9597), (0.15002790943951697, 0.95689999999999997), (0.1459303194877232, 0.95760000000000001), (0.14678537446227194, 0.95909999999999995), (0.14214705362081301, 0.96150000000000002), (0.1421936739170602, 0.96050000000000002), (0.14088370097875541, 0.95889999999999997), (0.14141438870739392, 0.96050000000000002), (0.14364370884789432, 0.96050000000000002), (0.143336842679649, 0.96150000000000002)], (0.13665804875365636, 0.95989999999999998))\n"
     ]
    }
   ],
   "source": [
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "print shelve_r['rotAug0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.579. Accuracy is 9.04%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 1.342. Accuracy is 77.98%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.372. Accuracy is 88.81%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 19 seconds. Training speed 498 pps. Validation speed 1462 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.338. Accuracy is 89.60%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.318. Accuracy is 90.68%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 19 seconds. Training speed 538 pps. Validation speed 1446 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.276. Accuracy is 91.50%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.268. Accuracy is 92.07%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 19 seconds. Training speed 539 pps. Validation speed 1442 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.224. Accuracy is 93.20%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.276. Accuracy is 91.74%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 18 seconds. Training speed 553 pps. Validation speed 1467 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.190. Accuracy is 94.21%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.234. Accuracy is 93.18%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 18 seconds. Training speed 537 pps. Validation speed 1484 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.159. Accuracy is 95.09%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.259. Accuracy is 92.74%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 18 seconds. Training speed 542 pps. Validation speed 1477 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.139. Accuracy is 95.97%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.223. Accuracy is 93.49%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 18 seconds. Training speed 542 pps. Validation speed 1448 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.113. Accuracy is 96.80%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.221. Accuracy is 93.62%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 19 seconds. Training speed 540 pps. Validation speed 1432 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.097. Accuracy is 97.23%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.208. Accuracy is 94.02%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 18 seconds. Training speed 538 pps. Validation speed 1463 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.083. Accuracy is 97.86%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.205. Accuracy is 94.23%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 18 seconds. Training speed 537 pps. Validation speed 1480 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.068. Accuracy is 98.40%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.210. Accuracy is 93.99%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 19 seconds. Training speed 541 pps. Validation speed 1441 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.060. Accuracy is 98.59%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.195. Accuracy is 94.64%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 19 seconds. Training speed 537 pps. Validation speed 1452 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.050. Accuracy is 99.06%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.195. Accuracy is 94.42%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 18 seconds. Training speed 541 pps. Validation speed 1472 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.042. Accuracy is 99.25%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.205. Accuracy is 94.18%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 19 seconds. Training speed 536 pps. Validation speed 1457 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.038. Accuracy is 99.36%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.193. Accuracy is 94.68%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 18 seconds. Training speed 547 pps. Validation speed 1446 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.031. Accuracy is 99.58%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.198. Accuracy is 94.48%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 18 seconds. Training speed 538 pps. Validation speed 1499 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.027. Accuracy is 99.73%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.197. Accuracy is 94.70%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 18 seconds. Training speed 544 pps. Validation speed 1462 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.023. Accuracy is 99.81%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.194. Accuracy is 94.72%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 19 seconds. Training speed 531 pps. Validation speed 1444 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.020. Accuracy is 99.89%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.198. Accuracy is 94.83%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 18 seconds. Training speed 544 pps. Validation speed 1465 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.018. Accuracy is 99.92%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.199. Accuracy is 94.82%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 18 seconds. Training speed 535 pps. Validation speed 1495 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.016. Accuracy is 99.94%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.197. Accuracy is 94.86%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 18 seconds. Training speed 545 pps. Validation speed 1445 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.015. Accuracy is 99.92%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.196. Accuracy is 94.78%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 19 seconds. Training speed 535 pps. Validation speed 1441 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.013. Accuracy is 99.97%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.194. Accuracy is 94.98%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 18 seconds. Training speed 537 pps. Validation speed 1472 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.012. Accuracy is 99.97%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.194. Accuracy is 95.02%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 19 seconds. Training speed 535 pps. Validation speed 1455 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.011. Accuracy is 99.97%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.195. Accuracy is 95.15%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 18 seconds. Training speed 560 pps. Validation speed 1473 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.010. Accuracy is 99.98%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.197. Accuracy is 94.97%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 18 seconds. Training speed 545 pps. Validation speed 1462 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.196. Accuracy is 95.03%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 19 seconds. Training speed 539 pps. Validation speed 1431 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.196. Accuracy is 95.07%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 19 seconds. Training speed 538 pps. Validation speed 1440 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.008. Accuracy is 99.98%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.200. Accuracy is 94.96%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 18 seconds. Training speed 548 pps. Validation speed 1454 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.200. Accuracy is 95.07%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 18 seconds. Training speed 548 pps. Validation speed 1492 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 94.89 %, cost (ce) is 0.198\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.379. Accuracy is 9.71%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.388. Accuracy is 11.22%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.287. Accuracy is 18.86%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 17 seconds. Training speed 588 pps. Validation speed 1475 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.016. Accuracy is 24.99%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 1.258. Accuracy is 53.43%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 17 seconds. Training speed 608 pps. Validation speed 1484 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.949. Accuracy is 65.95%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.619. Accuracy is 81.18%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 17 seconds. Training speed 594 pps. Validation speed 1435 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.560. Accuracy is 82.00%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.481. Accuracy is 84.69%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 18 seconds. Training speed 593 pps. Validation speed 1434 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.430. Accuracy is 86.43%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.368. Accuracy is 88.75%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 18 seconds. Training speed 589 pps. Validation speed 1443 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.359. Accuracy is 88.61%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.382. Accuracy is 87.84%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 17 seconds. Training speed 617 pps. Validation speed 1454 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.313. Accuracy is 89.89%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.350. Accuracy is 89.21%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 17 seconds. Training speed 588 pps. Validation speed 1484 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.271. Accuracy is 91.36%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.311. Accuracy is 90.76%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 17 seconds. Training speed 591 pps. Validation speed 1466 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.238. Accuracy is 92.46%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.333. Accuracy is 90.14%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 17 seconds. Training speed 592 pps. Validation speed 1441 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.197. Accuracy is 93.71%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.270. Accuracy is 92.31%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 17 seconds. Training speed 633 pps. Validation speed 1441 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.179. Accuracy is 94.67%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.247. Accuracy is 92.84%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 17 seconds. Training speed 600 pps. Validation speed 1443 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.149. Accuracy is 95.36%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.229. Accuracy is 93.37%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 17 seconds. Training speed 597 pps. Validation speed 1447 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.135. Accuracy is 95.68%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.246. Accuracy is 93.12%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 17 seconds. Training speed 583 pps. Validation speed 1478 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.114. Accuracy is 96.43%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.302. Accuracy is 91.58%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 17 seconds. Training speed 608 pps. Validation speed 1462 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.107. Accuracy is 96.61%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.216. Accuracy is 94.12%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 18 seconds. Training speed 586 pps. Validation speed 1441 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.086. Accuracy is 97.39%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.311. Accuracy is 91.63%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 18 seconds. Training speed 587 pps. Validation speed 1433 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.085. Accuracy is 97.57%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.229. Accuracy is 93.78%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 18 seconds. Training speed 588 pps. Validation speed 1455 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.069. Accuracy is 97.90%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.217. Accuracy is 94.30%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 17 seconds. Training speed 603 pps. Validation speed 1477 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.057. Accuracy is 98.11%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.246. Accuracy is 93.62%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 17 seconds. Training speed 591 pps. Validation speed 1480 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.043. Accuracy is 98.77%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.217. Accuracy is 94.36%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 18 seconds. Training speed 586 pps. Validation speed 1432 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.037. Accuracy is 99.01%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.245. Accuracy is 94.02%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 17 seconds. Training speed 605 pps. Validation speed 1438 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.029. Accuracy is 99.23%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.237. Accuracy is 94.44%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 17 seconds. Training speed 609 pps. Validation speed 1465 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.021. Accuracy is 99.50%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.287. Accuracy is 93.46%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 17 seconds. Training speed 588 pps. Validation speed 1485 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.018. Accuracy is 99.54%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.264. Accuracy is 93.88%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 17 seconds. Training speed 591 pps. Validation speed 1476 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.013. Accuracy is 99.71%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.234. Accuracy is 94.73%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 18 seconds. Training speed 595 pps. Validation speed 1426 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.010. Accuracy is 99.76%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.272. Accuracy is 94.11%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 17 seconds. Training speed 604 pps. Validation speed 1435 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.007. Accuracy is 99.92%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.242. Accuracy is 94.82%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 17 seconds. Training speed 587 pps. Validation speed 1483 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.005. Accuracy is 99.95%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.243. Accuracy is 94.93%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 17 seconds. Training speed 595 pps. Validation speed 1494 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.003. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.241. Accuracy is 95.10%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 17 seconds. Training speed 592 pps. Validation speed 1460 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.003. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.250. Accuracy is 94.90%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 17 seconds. Training speed 612 pps. Validation speed 1470 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 94.47 %, cost (ce) is 0.249\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=25, max_num_batches=250, randomize=True, augmentation = 3)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"dpAugExperimentsExp\", writeback = True)\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['dpAug'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(2.3790590745646085, 0.097119999999999734), (2.3881805605977542, 0.11215999999999977), (2.0159429450817039, 0.24991999999999995), (0.9488378819845753, 0.65952000000000055), (0.56004495608192173, 0.81999999999999995), (0.43044596275823094, 0.86431999999999976), (0.3591867620434484, 0.88607999999999898), (0.3134910808457535, 0.89887999999999935), (0.27059952836536155, 0.91359999999999841), (0.23750517326524775, 0.92463999999999913), (0.19672232450051497, 0.93711999999999929), (0.17857337194467107, 0.94671999999999878), (0.14944613340522162, 0.95359999999999967), (0.13530647543698449, 0.95680000000000009), (0.11397150207736742, 0.96431999999999995), (0.10661750135426776, 0.96607999999999994), (0.085781599460168917, 0.97392000000000023), (0.085140905375646961, 0.97568000000000044), (0.069225186659928897, 0.97904000000000013), (0.056527742859424662, 0.98112000000000021), (0.042557410028629845, 0.98768000000000056), (0.036852946536831258, 0.99008000000000007), (0.028968091205064595, 0.99232000000000031), (0.020642556724592118, 0.99504000000000004), (0.018345463493992187, 0.99536000000000036), (0.012932954738798812, 0.99712000000000034), (0.0097913083807184779, 0.99760000000000026), (0.0067620033908514709, 0.9992000000000002), (0.0049777841975428014, 0.99951999999999996), (0.0034329878148066789, 1.0), (0.0029382905553417514, 1.0)], [(2.3795721363921292, 0.1009), (2.2870595086298544, 0.18859999999999999), (1.2583921548579962, 0.5343), (0.61943436658812467, 0.81179999999999997), (0.48091878987227626, 0.84689999999999999), (0.36814196518406611, 0.88749999999999996), (0.38193207675845908, 0.87839999999999996), (0.3500829633983672, 0.8921), (0.31127231382293258, 0.90759999999999996), (0.33287585330294084, 0.90139999999999998), (0.26981661522272887, 0.92310000000000003), (0.24702918795892229, 0.9284), (0.22856847138418115, 0.93369999999999997), (0.24640382024693905, 0.93120000000000003), (0.30237129943784413, 0.91579999999999995), (0.21635973716799872, 0.94120000000000004), (0.31092850258101201, 0.9163), (0.22934918507046131, 0.93779999999999997), (0.2167664864776768, 0.94299999999999995), (0.24629810621415435, 0.93620000000000003), (0.217343501403954, 0.94359999999999999), (0.24463818470061247, 0.94020000000000004), (0.23732513585426604, 0.94440000000000002), (0.28681518158174052, 0.93459999999999999), (0.26401849177473202, 0.93879999999999997), (0.23416685031046749, 0.94730000000000003), (0.27204246769812768, 0.94110000000000005), (0.24209319720095895, 0.94820000000000004), (0.24303978728220677, 0.94930000000000003), (0.24050231667869898, 0.95099999999999996), (0.24998847324140383, 0.94899999999999995)], (0.24896832462710822, 0.94469999999999998))\n"
     ]
    }
   ],
   "source": [
    "shelve_r = shelve.open(\"dpAugExperimentsExp\")\n",
    "\n",
    "print shelve_r['dpAug1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Shift Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.583. Accuracy is 8.58%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 1.743. Accuracy is 64.68%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.566. Accuracy is 82.79%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 19 seconds. Training speed 509 pps. Validation speed 1476 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.629. Accuracy is 81.30%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.412. Accuracy is 87.82%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 18 seconds. Training speed 571 pps. Validation speed 1455 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.500. Accuracy is 85.26%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.329. Accuracy is 91.31%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 18 seconds. Training speed 557 pps. Validation speed 1471 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.404. Accuracy is 88.26%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.290. Accuracy is 91.96%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 18 seconds. Training speed 558 pps. Validation speed 1480 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.353. Accuracy is 89.86%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.257. Accuracy is 92.63%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 18 seconds. Training speed 553 pps. Validation speed 1453 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.301. Accuracy is 91.34%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.233. Accuracy is 93.56%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 18 seconds. Training speed 555 pps. Validation speed 1419 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.260. Accuracy is 92.46%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.211. Accuracy is 94.05%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 18 seconds. Training speed 556 pps. Validation speed 1461 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.234. Accuracy is 93.38%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.207. Accuracy is 94.38%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 18 seconds. Training speed 560 pps. Validation speed 1483 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.213. Accuracy is 93.91%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.189. Accuracy is 94.98%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 18 seconds. Training speed 560 pps. Validation speed 1448 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.197. Accuracy is 94.42%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.198. Accuracy is 94.62%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 18 seconds. Training speed 557 pps. Validation speed 1466 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.177. Accuracy is 94.98%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.174. Accuracy is 95.06%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 18 seconds. Training speed 568 pps. Validation speed 1466 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.163. Accuracy is 95.30%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.192. Accuracy is 94.61%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 18 seconds. Training speed 555 pps. Validation speed 1471 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.145. Accuracy is 96.00%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.154. Accuracy is 95.62%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 18 seconds. Training speed 555 pps. Validation speed 1454 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.142. Accuracy is 96.10%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.156. Accuracy is 95.40%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 18 seconds. Training speed 558 pps. Validation speed 1437 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.131. Accuracy is 96.50%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.160. Accuracy is 94.99%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 18 seconds. Training speed 583 pps. Validation speed 1442 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.121. Accuracy is 96.60%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.164. Accuracy is 95.13%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 18 seconds. Training speed 557 pps. Validation speed 1470 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.121. Accuracy is 96.71%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.143. Accuracy is 95.92%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 18 seconds. Training speed 552 pps. Validation speed 1429 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.112. Accuracy is 97.00%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.149. Accuracy is 95.52%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 18 seconds. Training speed 554 pps. Validation speed 1434 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.104. Accuracy is 97.22%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.161. Accuracy is 95.28%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 18 seconds. Training speed 580 pps. Validation speed 1484 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.100. Accuracy is 97.41%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.133. Accuracy is 96.11%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 18 seconds. Training speed 555 pps. Validation speed 1443 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.095. Accuracy is 97.49%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.138. Accuracy is 96.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 18 seconds. Training speed 552 pps. Validation speed 1431 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.084. Accuracy is 97.78%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.130. Accuracy is 96.21%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 18 seconds. Training speed 553 pps. Validation speed 1452 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.083. Accuracy is 97.77%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.137. Accuracy is 96.08%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 18 seconds. Training speed 566 pps. Validation speed 1473 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.083. Accuracy is 97.83%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.126. Accuracy is 96.27%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 18 seconds. Training speed 554 pps. Validation speed 1427 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.080. Accuracy is 97.79%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.125. Accuracy is 96.46%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 18 seconds. Training speed 557 pps. Validation speed 1464 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.078. Accuracy is 97.87%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.125. Accuracy is 96.34%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 18 seconds. Training speed 552 pps. Validation speed 1471 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.072. Accuracy is 98.14%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.124. Accuracy is 96.41%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 18 seconds. Training speed 565 pps. Validation speed 1458 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.072. Accuracy is 98.06%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.125. Accuracy is 96.39%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 18 seconds. Training speed 559 pps. Validation speed 1424 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.067. Accuracy is 98.26%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.123. Accuracy is 96.39%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 18 seconds. Training speed 554 pps. Validation speed 1481 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.067. Accuracy is 98.33%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.122. Accuracy is 96.39%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 18 seconds. Training speed 555 pps. Validation speed 1459 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 96.59 %, cost (ce) is 0.120\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.379. Accuracy is 9.71%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.383. Accuracy is 10.41%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.291. Accuracy is 9.83%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 17 seconds. Training speed 615 pps. Validation speed 1436 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.166. Accuracy is 18.49%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 1.764. Accuracy is 32.81%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 17 seconds. Training speed 606 pps. Validation speed 1464 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 1.390. Accuracy is 49.51%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 1.005. Accuracy is 62.96%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 17 seconds. Training speed 614 pps. Validation speed 1444 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.979. Accuracy is 66.57%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.624. Accuracy is 79.78%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 17 seconds. Training speed 616 pps. Validation speed 1474 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.775. Accuracy is 74.41%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.503. Accuracy is 84.08%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 17 seconds. Training speed 635 pps. Validation speed 1469 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.647. Accuracy is 79.24%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.443. Accuracy is 86.43%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 17 seconds. Training speed 608 pps. Validation speed 1421 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.568. Accuracy is 81.83%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.389. Accuracy is 88.30%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 17 seconds. Training speed 625 pps. Validation speed 1434 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.502. Accuracy is 84.04%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.330. Accuracy is 90.13%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 17 seconds. Training speed 611 pps. Validation speed 1462 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.432. Accuracy is 86.34%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.313. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 17 seconds. Training speed 633 pps. Validation speed 1482 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.391. Accuracy is 87.62%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.268. Accuracy is 92.07%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 17 seconds. Training speed 611 pps. Validation speed 1435 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.350. Accuracy is 89.33%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.281. Accuracy is 91.75%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 17 seconds. Training speed 630 pps. Validation speed 1425 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.316. Accuracy is 90.18%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.247. Accuracy is 92.62%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 17 seconds. Training speed 614 pps. Validation speed 1450 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.282. Accuracy is 91.20%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.230. Accuracy is 93.23%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 17 seconds. Training speed 635 pps. Validation speed 1484 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.256. Accuracy is 92.34%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.203. Accuracy is 94.28%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 17 seconds. Training speed 617 pps. Validation speed 1478 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.234. Accuracy is 92.93%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.226. Accuracy is 93.50%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 17 seconds. Training speed 623 pps. Validation speed 1430 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.217. Accuracy is 93.32%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.186. Accuracy is 94.52%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 17 seconds. Training speed 615 pps. Validation speed 1448 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.210. Accuracy is 93.54%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.187. Accuracy is 94.59%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 17 seconds. Training speed 623 pps. Validation speed 1470 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.198. Accuracy is 93.73%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.200. Accuracy is 94.03%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 17 seconds. Training speed 612 pps. Validation speed 1456 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.185. Accuracy is 94.26%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.251. Accuracy is 92.41%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 17 seconds. Training speed 613 pps. Validation speed 1421 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.160. Accuracy is 95.16%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.193. Accuracy is 94.35%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 17 seconds. Training speed 611 pps. Validation speed 1418 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.156. Accuracy is 95.33%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.174. Accuracy is 94.80%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 17 seconds. Training speed 613 pps. Validation speed 1416 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.147. Accuracy is 95.41%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.166. Accuracy is 94.99%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 17 seconds. Training speed 633 pps. Validation speed 1480 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.131. Accuracy is 95.85%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.170. Accuracy is 95.16%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 17 seconds. Training speed 620 pps. Validation speed 1465 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.132. Accuracy is 96.07%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.180. Accuracy is 94.80%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 17 seconds. Training speed 612 pps. Validation speed 1437 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.123. Accuracy is 96.28%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.174. Accuracy is 95.24%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 17 seconds. Training speed 620 pps. Validation speed 1472 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.120. Accuracy is 96.38%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.171. Accuracy is 95.33%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 17 seconds. Training speed 640 pps. Validation speed 1458 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.113. Accuracy is 96.50%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.270. Accuracy is 92.27%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 17 seconds. Training speed 612 pps. Validation speed 1428 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.111. Accuracy is 96.47%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.145. Accuracy is 95.86%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 17 seconds. Training speed 615 pps. Validation speed 1478 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.101. Accuracy is 96.80%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.160. Accuracy is 95.40%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 17 seconds. Training speed 611 pps. Validation speed 1449 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.097. Accuracy is 97.02%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.157. Accuracy is 95.67%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 17 seconds. Training speed 651 pps. Validation speed 1444 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 95.69 %, cost (ce) is 0.153\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=25, max_num_batches=250, randomize=True, augmentation = 4)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"siAugExperimentsExp\", writeback = True)\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['siAug'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(2.5829580850249796, 0.085839999999999875), (1.7430002116563719, 0.64679999999999982), (0.62902550636653609, 0.81296000000000068), (0.50014567509224994, 0.85263999999999995), (0.4035487772071924, 0.88264000000000031), (0.35274842068266349, 0.89863999999999999), (0.30100346418398144, 0.91335999999999928), (0.2598261973346489, 0.92463999999999946), (0.23432229657982687, 0.93383999999999912), (0.21334208495475118, 0.9391199999999994), (0.19656201028969406, 0.944159999999999), (0.1774417412380915, 0.94975999999999927), (0.16347796582529248, 0.9529599999999987), (0.14495680404014663, 0.95999999999999952), (0.14157464820182641, 0.96103999999999867), (0.13083536725362305, 0.96495999999999871), (0.12079940992067965, 0.96599999999999864), (0.12074252957259465, 0.96711999999999909), (0.11185988883895207, 0.96999999999999953), (0.10393038768356934, 0.97215999999999858), (0.10013463862822616, 0.97407999999999872), (0.095163652272800922, 0.97487999999999841), (0.084308039195903225, 0.97783999999999904), (0.083125576520665628, 0.97767999999999866), (0.082911720051512927, 0.97831999999999908), (0.079788864989225453, 0.9779199999999989), (0.078223811539007676, 0.97871999999999804), (0.071579662914380032, 0.98135999999999857), (0.071983400244940626, 0.98063999999999873), (0.066609218229847, 0.98255999999999954), (0.067476736940678364, 0.98327999999999838)], [(2.5535497258761009, 0.098400000000000001), (0.56632882819232488, 0.82789999999999997), (0.41167083273404714, 0.87819999999999998), (0.32858829509328619, 0.91310000000000002), (0.29011421087788225, 0.91959999999999997), (0.25651678872361205, 0.92630000000000001), (0.23346781567174743, 0.93559999999999999), (0.21097066181564564, 0.9405), (0.20678928456340037, 0.94379999999999997), (0.1889672153924058, 0.94979999999999998), (0.19786920399556668, 0.94620000000000004), (0.17361201058376224, 0.9506), (0.19211658127821882, 0.94610000000000005), (0.15449000571942989, 0.95620000000000005), (0.15629012465170061, 0.95399999999999996), (0.16034622296445386, 0.94989999999999997), (0.16410990896401859, 0.95130000000000003), (0.14336095096872459, 0.95920000000000005), (0.14920580293774274, 0.95520000000000005), (0.16112030117402101, 0.95279999999999998), (0.132834025813863, 0.96109999999999995), (0.1375022815800975, 0.95999999999999996), (0.12998246574871475, 0.96209999999999996), (0.13657219430779946, 0.96079999999999999), (0.12592613666959518, 0.9627), (0.12536029521754524, 0.96460000000000001), (0.12531077050019718, 0.96340000000000003), (0.12425834342426401, 0.96409999999999996), (0.12527306061329624, 0.96389999999999998), (0.12254949420268799, 0.96389999999999998), (0.12207721504667415, 0.96389999999999998)], (0.119780710114536, 0.96589999999999998))\n"
     ]
    }
   ],
   "source": [
    "shelve_r = shelve.open(\"siAugExperimentsExp\")\n",
    "\n",
    "print shelve_r['siAug0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.576. Accuracy is 8.94%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 1.561. Accuracy is 71.10%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.430. Accuracy is 87.57%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 15 seconds. Training speed 640 pps. Validation speed 1878 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.546. Accuracy is 84.19%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.366. Accuracy is 89.49%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 16 seconds. Training speed 629 pps. Validation speed 1762 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.445. Accuracy is 87.37%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.303. Accuracy is 90.87%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 16 seconds. Training speed 616 pps. Validation speed 1778 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.381. Accuracy is 89.10%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.300. Accuracy is 91.58%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 15 seconds. Training speed 636 pps. Validation speed 1807 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.335. Accuracy is 90.31%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.261. Accuracy is 92.94%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 15 seconds. Training speed 635 pps. Validation speed 1892 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.281. Accuracy is 92.23%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.251. Accuracy is 93.03%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 16 seconds. Training speed 618 pps. Validation speed 1801 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.245. Accuracy is 93.29%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.227. Accuracy is 93.58%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 15 seconds. Training speed 645 pps. Validation speed 1833 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.209. Accuracy is 94.10%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.208. Accuracy is 94.06%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 16 seconds. Training speed 600 pps. Validation speed 1689 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.189. Accuracy is 94.70%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.183. Accuracy is 94.92%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 16 seconds. Training speed 618 pps. Validation speed 1826 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.170. Accuracy is 95.50%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.178. Accuracy is 95.15%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 16 seconds. Training speed 621 pps. Validation speed 1629 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.149. Accuracy is 95.90%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.161. Accuracy is 95.34%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 16 seconds. Training speed 609 pps. Validation speed 1804 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.139. Accuracy is 96.48%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.155. Accuracy is 95.60%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 16 seconds. Training speed 618 pps. Validation speed 1802 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.125. Accuracy is 96.56%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.159. Accuracy is 95.55%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 16 seconds. Training speed 633 pps. Validation speed 1753 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.113. Accuracy is 97.27%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.147. Accuracy is 95.76%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 16 seconds. Training speed 624 pps. Validation speed 1790 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.105. Accuracy is 97.26%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.164. Accuracy is 95.12%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 16 seconds. Training speed 629 pps. Validation speed 1788 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.099. Accuracy is 97.60%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.148. Accuracy is 95.87%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 16 seconds. Training speed 625 pps. Validation speed 1781 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.093. Accuracy is 97.85%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.138. Accuracy is 96.14%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 16 seconds. Training speed 610 pps. Validation speed 1672 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.093. Accuracy is 97.86%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.136. Accuracy is 96.09%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 16 seconds. Training speed 580 pps. Validation speed 1789 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.079. Accuracy is 98.04%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.135. Accuracy is 96.02%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 16 seconds. Training speed 598 pps. Validation speed 1817 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.075. Accuracy is 98.26%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.141. Accuracy is 95.90%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 16 seconds. Training speed 623 pps. Validation speed 1761 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.073. Accuracy is 98.15%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.134. Accuracy is 96.20%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 15 seconds. Training speed 639 pps. Validation speed 1784 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.073. Accuracy is 98.14%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.133. Accuracy is 96.13%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 16 seconds. Training speed 610 pps. Validation speed 1730 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.067. Accuracy is 98.50%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.132. Accuracy is 96.08%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 15 seconds. Training speed 628 pps. Validation speed 1847 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.063. Accuracy is 98.46%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.129. Accuracy is 96.40%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 16 seconds. Training speed 612 pps. Validation speed 1767 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.059. Accuracy is 98.62%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.128. Accuracy is 96.41%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 16 seconds. Training speed 632 pps. Validation speed 1759 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.060. Accuracy is 98.57%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.129. Accuracy is 96.11%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 15 seconds. Training speed 633 pps. Validation speed 1797 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.056. Accuracy is 98.76%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.129. Accuracy is 96.27%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 16 seconds. Training speed 633 pps. Validation speed 1770 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.056. Accuracy is 98.70%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.129. Accuracy is 96.30%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 16 seconds. Training speed 608 pps. Validation speed 1803 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.051. Accuracy is 98.82%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.124. Accuracy is 96.37%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 15 seconds. Training speed 629 pps. Validation speed 1817 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.052. Accuracy is 98.81%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.125. Accuracy is 96.41%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 16 seconds. Training speed 627 pps. Validation speed 1790 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 96.47 %, cost (ce) is 0.120\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.379. Accuracy is 9.71%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.395. Accuracy is 10.72%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.303. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 14 seconds. Training speed 718 pps. Validation speed 1873 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.292. Accuracy is 12.78%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 2.217. Accuracy is 27.07%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 14 seconds. Training speed 739 pps. Validation speed 1926 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 1.777. Accuracy is 34.82%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 1.193. Accuracy is 52.65%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 14 seconds. Training speed 711 pps. Validation speed 1889 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 1.020. Accuracy is 65.54%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.601. Accuracy is 81.07%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 14 seconds. Training speed 724 pps. Validation speed 1903 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.741. Accuracy is 76.72%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.449. Accuracy is 86.75%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 14 seconds. Training speed 721 pps. Validation speed 1839 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.608. Accuracy is 81.30%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.399. Accuracy is 87.93%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 14 seconds. Training speed 736 pps. Validation speed 1857 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.526. Accuracy is 83.87%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.372. Accuracy is 88.38%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 14 seconds. Training speed 715 pps. Validation speed 1816 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.461. Accuracy is 85.74%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.311. Accuracy is 90.63%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 14 seconds. Training speed 695 pps. Validation speed 1902 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.422. Accuracy is 86.63%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.301. Accuracy is 90.67%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 14 seconds. Training speed 724 pps. Validation speed 1842 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.383. Accuracy is 87.94%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.272. Accuracy is 91.68%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 14 seconds. Training speed 724 pps. Validation speed 1896 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.346. Accuracy is 89.32%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.274. Accuracy is 91.80%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 14 seconds. Training speed 709 pps. Validation speed 1856 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.296. Accuracy is 91.03%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.249. Accuracy is 92.33%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 14 seconds. Training speed 716 pps. Validation speed 1896 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.289. Accuracy is 91.00%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.263. Accuracy is 92.10%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 14 seconds. Training speed 711 pps. Validation speed 1895 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.253. Accuracy is 92.38%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.226. Accuracy is 93.09%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 14 seconds. Training speed 718 pps. Validation speed 1986 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.226. Accuracy is 93.08%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.214. Accuracy is 93.67%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 14 seconds. Training speed 722 pps. Validation speed 1906 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.212. Accuracy is 93.57%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.216. Accuracy is 93.72%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 14 seconds. Training speed 699 pps. Validation speed 1900 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.199. Accuracy is 94.02%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.174. Accuracy is 95.03%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 14 seconds. Training speed 718 pps. Validation speed 1873 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.165. Accuracy is 95.24%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.202. Accuracy is 94.23%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 14 seconds. Training speed 710 pps. Validation speed 1977 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.160. Accuracy is 95.20%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.175. Accuracy is 94.52%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 14 seconds. Training speed 710 pps. Validation speed 1886 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.136. Accuracy is 96.15%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.209. Accuracy is 94.20%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 14 seconds. Training speed 741 pps. Validation speed 1773 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.127. Accuracy is 96.24%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.184. Accuracy is 94.69%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 15 seconds. Training speed 674 pps. Validation speed 1788 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.116. Accuracy is 96.69%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.166. Accuracy is 95.17%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 14 seconds. Training speed 709 pps. Validation speed 1799 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.116. Accuracy is 96.54%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.161. Accuracy is 95.43%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 14 seconds. Training speed 686 pps. Validation speed 1894 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.102. Accuracy is 97.12%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.169. Accuracy is 95.29%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 14 seconds. Training speed 755 pps. Validation speed 1876 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.097. Accuracy is 97.02%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.170. Accuracy is 95.24%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 14 seconds. Training speed 751 pps. Validation speed 1884 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.092. Accuracy is 97.37%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.159. Accuracy is 95.57%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 14 seconds. Training speed 716 pps. Validation speed 1832 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.092. Accuracy is 97.30%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.173. Accuracy is 95.30%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 14 seconds. Training speed 750 pps. Validation speed 1827 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.080. Accuracy is 97.64%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.166. Accuracy is 95.44%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 14 seconds. Training speed 717 pps. Validation speed 1862 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.091. Accuracy is 97.19%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.208. Accuracy is 94.13%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 14 seconds. Training speed 722 pps. Validation speed 1890 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.073. Accuracy is 97.73%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.177. Accuracy is 95.17%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 15 seconds. Training speed 687 pps. Validation speed 1834 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 95.48 %, cost (ce) is 0.165\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=25, max_num_batches=250, randomize=True, augmentation = 5)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['ranAug'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(2.5764682227846394, 0.089439999999999811), (1.5609751983696472, 0.71104000000000056), (0.54552691188002445, 0.84192000000000022), (0.44474780014951787, 0.87368000000000046), (0.38089699144193384, 0.89104000000000005), (0.33450930787410083, 0.90312000000000048), (0.28111618041248881, 0.92231999999999958), (0.2445538690417324, 0.93287999999999927), (0.20922008233164727, 0.94103999999999932), (0.18941796677622746, 0.9469599999999988), (0.16984181609687674, 0.95503999999999878), (0.14939115243557247, 0.95903999999999889), (0.13943360034734933, 0.96479999999999866), (0.12470625478090855, 0.96559999999999924), (0.11335153012250314, 0.97271999999999914), (0.10506183880711599, 0.97263999999999884), (0.099271112707728537, 0.97599999999999931), (0.092739087160186875, 0.97847999999999846), (0.092797675219459252, 0.97863999999999884), (0.079184470418435765, 0.98039999999999861), (0.075331608062100874, 0.98255999999999832), (0.072937061354576366, 0.98151999999999895), (0.07320546749959457, 0.98143999999999842), (0.066812475656684675, 0.98503999999999858), (0.063141379330105329, 0.98463999999999896), (0.059441830592227393, 0.98623999999999934), (0.059505719052917717, 0.98567999999999878), (0.055844066364537412, 0.98759999999999837), (0.05627042319058153, 0.98695999999999873), (0.050768521738684201, 0.98815999999999893), (0.051514689595047375, 0.98807999999999863)], [(2.5535497258761009, 0.098400000000000001), (0.42950846303533574, 0.87570000000000003), (0.36633853396523025, 0.89490000000000003), (0.30312223335450028, 0.90869999999999995), (0.29973977680142549, 0.91579999999999995), (0.26148935126052603, 0.9294), (0.25078757766645904, 0.93030000000000002), (0.2269921174407612, 0.93579999999999997), (0.20813730640478292, 0.94059999999999999), (0.18344012004481314, 0.94920000000000004), (0.17777984132471442, 0.95150000000000001), (0.16112643173359609, 0.95340000000000003), (0.15545742655515582, 0.95599999999999996), (0.15861021523544036, 0.95550000000000002), (0.14715460913297757, 0.95760000000000001), (0.1644013093522885, 0.95120000000000005), (0.14845442849221135, 0.9587), (0.13761880763340545, 0.96140000000000003), (0.13613548003037609, 0.96089999999999998), (0.13535366523322484, 0.96020000000000005), (0.14071446490030129, 0.95899999999999996), (0.13418408500476303, 0.96199999999999997), (0.13335496605237773, 0.96130000000000004), (0.13216752255465908, 0.96079999999999999), (0.12889259287657281, 0.96399999999999997), (0.12848034734130909, 0.96409999999999996), (0.1289382837082563, 0.96109999999999995), (0.1292296481322662, 0.9627), (0.12856114079054881, 0.96299999999999997), (0.1244286717764785, 0.9637), (0.12518512629619757, 0.96409999999999996)], (0.11993297480218293, 0.9647))\n"
     ]
    }
   ],
   "source": [
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "print shelve_r['ranAug0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.612. Accuracy is 8.54%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 3.339. Accuracy is 50.46%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.716. Accuracy is 78.08%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 9 seconds. Training speed 249 pps. Validation speed 1873 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.927. Accuracy is 71.14%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.526. Accuracy is 83.48%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 10 seconds. Training speed 236 pps. Validation speed 1753 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.740. Accuracy is 77.06%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.489. Accuracy is 85.75%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 10 seconds. Training speed 229 pps. Validation speed 1807 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.652. Accuracy is 80.84%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.441. Accuracy is 87.25%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 10 seconds. Training speed 233 pps. Validation speed 1817 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.536. Accuracy is 84.12%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.444. Accuracy is 85.97%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 10 seconds. Training speed 235 pps. Validation speed 1832 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.482. Accuracy is 85.78%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.449. Accuracy is 87.16%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 9 seconds. Training speed 230 pps. Validation speed 1951 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.430. Accuracy is 88.20%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.368. Accuracy is 89.67%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 10 seconds. Training speed 231 pps. Validation speed 1806 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.384. Accuracy is 88.98%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.346. Accuracy is 90.32%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 10 seconds. Training speed 237 pps. Validation speed 1865 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.333. Accuracy is 91.12%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.378. Accuracy is 89.17%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 10 seconds. Training speed 228 pps. Validation speed 1835 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.311. Accuracy is 91.52%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.335. Accuracy is 90.34%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 10 seconds. Training speed 230 pps. Validation speed 1876 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.275. Accuracy is 92.04%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.356. Accuracy is 89.57%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 10 seconds. Training speed 237 pps. Validation speed 1840 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.251. Accuracy is 93.54%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.347. Accuracy is 89.71%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 10 seconds. Training speed 247 pps. Validation speed 1788 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.219. Accuracy is 94.12%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.305. Accuracy is 91.40%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 10 seconds. Training speed 229 pps. Validation speed 1815 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.198. Accuracy is 94.54%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.378. Accuracy is 88.91%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 10 seconds. Training speed 231 pps. Validation speed 1866 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.180. Accuracy is 95.38%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.322. Accuracy is 90.94%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 10 seconds. Training speed 238 pps. Validation speed 1821 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.183. Accuracy is 95.04%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.350. Accuracy is 90.09%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 10 seconds. Training speed 230 pps. Validation speed 1805 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.163. Accuracy is 95.70%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.289. Accuracy is 91.92%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 9 seconds. Training speed 242 pps. Validation speed 1899 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.165. Accuracy is 95.40%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.310. Accuracy is 91.45%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 10 seconds. Training speed 237 pps. Validation speed 1836 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.144. Accuracy is 96.12%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.318. Accuracy is 90.45%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 10 seconds. Training speed 237 pps. Validation speed 1798 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.143. Accuracy is 96.22%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.298. Accuracy is 91.11%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 10 seconds. Training speed 235 pps. Validation speed 1799 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.127. Accuracy is 96.86%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.290. Accuracy is 91.82%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 10 seconds. Training speed 235 pps. Validation speed 1812 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.132. Accuracy is 96.28%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.291. Accuracy is 91.50%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 10 seconds. Training speed 236 pps. Validation speed 1849 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.121. Accuracy is 96.82%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.270. Accuracy is 92.59%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 10 seconds. Training speed 247 pps. Validation speed 1826 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.115. Accuracy is 96.90%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.268. Accuracy is 92.57%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 10 seconds. Training speed 225 pps. Validation speed 1795 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.118. Accuracy is 97.10%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.286. Accuracy is 92.30%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 10 seconds. Training speed 237 pps. Validation speed 1811 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.102. Accuracy is 97.36%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.284. Accuracy is 91.83%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 10 seconds. Training speed 239 pps. Validation speed 1816 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.101. Accuracy is 97.26%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.277. Accuracy is 92.11%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 10 seconds. Training speed 229 pps. Validation speed 1833 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.100. Accuracy is 97.44%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.271. Accuracy is 92.50%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 9 seconds. Training speed 235 pps. Validation speed 1911 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.097. Accuracy is 97.54%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.285. Accuracy is 92.02%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 10 seconds. Training speed 229 pps. Validation speed 1831 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.088. Accuracy is 97.56%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.264. Accuracy is 92.72%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 10 seconds. Training speed 238 pps. Validation speed 1820 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 92.35 %, cost (ce) is 0.265\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.377. Accuracy is 9.10%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.380. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.542. Accuracy is 11.62%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 2.308. Accuracy is 10.64%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 9 seconds. Training speed 273 pps. Validation speed 1911 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 2.316. Accuracy is 9.76%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 2.307. Accuracy is 10.30%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 9 seconds. Training speed 264 pps. Validation speed 1968 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 2.314. Accuracy is 9.26%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 2.311. Accuracy is 10.64%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 9 seconds. Training speed 271 pps. Validation speed 1959 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 2.311. Accuracy is 11.14%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 2.307. Accuracy is 9.61%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 9 seconds. Training speed 270 pps. Validation speed 1918 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 2.306. Accuracy is 9.92%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 2.295. Accuracy is 18.82%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 9 seconds. Training speed 273 pps. Validation speed 1904 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 2.291. Accuracy is 12.94%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 2.269. Accuracy is 10.93%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 9 seconds. Training speed 274 pps. Validation speed 1877 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 2.202. Accuracy is 18.96%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 1.986. Accuracy is 22.25%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 9 seconds. Training speed 270 pps. Validation speed 1893 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 2.008. Accuracy is 25.52%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 1.702. Accuracy is 38.27%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 9 seconds. Training speed 290 pps. Validation speed 1860 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 1.695. Accuracy is 36.98%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 1.274. Accuracy is 50.53%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 9 seconds. Training speed 263 pps. Validation speed 1868 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 1.396. Accuracy is 49.06%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 1.066. Accuracy is 61.62%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 9 seconds. Training speed 269 pps. Validation speed 1923 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 1.228. Accuracy is 56.54%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.940. Accuracy is 68.50%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 9 seconds. Training speed 256 pps. Validation speed 1808 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 1.084. Accuracy is 63.26%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.772. Accuracy is 74.59%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 10 seconds. Training speed 242 pps. Validation speed 1806 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.996. Accuracy is 65.28%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.671. Accuracy is 78.12%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 10 seconds. Training speed 245 pps. Validation speed 1801 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.923. Accuracy is 69.54%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.669. Accuracy is 79.90%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 10 seconds. Training speed 233 pps. Validation speed 1720 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.847. Accuracy is 71.70%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.690. Accuracy is 77.24%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 10 seconds. Training speed 240 pps. Validation speed 1777 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.771. Accuracy is 74.38%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.656. Accuracy is 77.90%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 9 seconds. Training speed 258 pps. Validation speed 1868 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.737. Accuracy is 74.92%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.591. Accuracy is 81.47%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 9 seconds. Training speed 259 pps. Validation speed 1787 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.699. Accuracy is 76.44%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.496. Accuracy is 84.52%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 9 seconds. Training speed 251 pps. Validation speed 1857 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.607. Accuracy is 79.26%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.660. Accuracy is 80.76%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 9 seconds. Training speed 251 pps. Validation speed 1830 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.595. Accuracy is 80.56%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.567. Accuracy is 80.44%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 9 seconds. Training speed 263 pps. Validation speed 1869 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.529. Accuracy is 83.20%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.462. Accuracy is 85.58%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 10 seconds. Training speed 250 pps. Validation speed 1812 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.493. Accuracy is 84.46%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.454. Accuracy is 86.20%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 9 seconds. Training speed 273 pps. Validation speed 1904 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.474. Accuracy is 84.96%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.413. Accuracy is 87.61%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 9 seconds. Training speed 264 pps. Validation speed 1996 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.457. Accuracy is 85.46%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.420. Accuracy is 87.32%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 9 seconds. Training speed 272 pps. Validation speed 1901 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.389. Accuracy is 88.04%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.387. Accuracy is 88.20%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 9 seconds. Training speed 263 pps. Validation speed 1861 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.365. Accuracy is 89.34%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.441. Accuracy is 87.13%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 9 seconds. Training speed 250 pps. Validation speed 1837 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.356. Accuracy is 88.82%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.361. Accuracy is 89.10%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 9 seconds. Training speed 267 pps. Validation speed 1869 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.340. Accuracy is 89.58%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.346. Accuracy is 89.94%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 9 seconds. Training speed 270 pps. Validation speed 1738 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.317. Accuracy is 89.78%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.404. Accuracy is 88.18%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 9 seconds. Training speed 292 pps. Validation speed 1874 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.308. Accuracy is 90.62%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.413. Accuracy is 88.56%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 9 seconds. Training speed 265 pps. Validation speed 1855 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 87.89 %, cost (ce) is 0.422\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=10, max_num_batches=100, randomize=True, augmentation = 6)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "l2_weight = 0.000\n",
    "dp_scheduler = None\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['allAug'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(2.6121181065285213, 0.085399999999999934), (3.3386188054325641, 0.50460000000000005), (0.92744783493968019, 0.71140000000000014), (0.73978559840762348, 0.77060000000000017), (0.65191161521539442, 0.80840000000000001), (0.5356441589359745, 0.84120000000000017), (0.48156223556080574, 0.85779999999999967), (0.42952588115839468, 0.88200000000000012), (0.3837260789334026, 0.88980000000000004), (0.33331038473017471, 0.9111999999999999), (0.31116090080893472, 0.91519999999999957), (0.27474795056682294, 0.92039999999999988), (0.25136101986779752, 0.9353999999999999), (0.21947064786448864, 0.94119999999999937), (0.19793114700923031, 0.94539999999999946), (0.17974359308773238, 0.95379999999999943), (0.18305838239454297, 0.95039999999999936), (0.16257642352225748, 0.95699999999999985), (0.16464408652818271, 0.95400000000000007), (0.1438111786511668, 0.9611999999999995), (0.14314446972757594, 0.96219999999999939), (0.12716693398533691, 0.96859999999999946), (0.13241150587049533, 0.96279999999999977), (0.12068308820832811, 0.96819999999999917), (0.11546354675799775, 0.96900000000000008), (0.11805480551758075, 0.97099999999999942), (0.10242067540916651, 0.97359999999999924), (0.10141303594253075, 0.9725999999999998), (0.099547267069103912, 0.97439999999999982), (0.096912893551000162, 0.9753999999999996), (0.088059261918242648, 0.97559999999999969)], [(2.5535497258761009, 0.098400000000000001), (0.71594241389670832, 0.78080000000000005), (0.52622499808529122, 0.83479999999999999), (0.48876468753833607, 0.85750000000000004), (0.44148080812452029, 0.87250000000000005), (0.44448365445892357, 0.85970000000000002), (0.44902268720658839, 0.87160000000000004), (0.36844807101202837, 0.89670000000000005), (0.34600993066572661, 0.9032), (0.37798804525467922, 0.89170000000000005), (0.33489942131395717, 0.90339999999999998), (0.3563275315819055, 0.89570000000000005), (0.34651449538728785, 0.89710000000000001), (0.30476095189236235, 0.91400000000000003), (0.37769567026557049, 0.8891), (0.32192956326135275, 0.90939999999999999), (0.35008866557796592, 0.90090000000000003), (0.28869389968738374, 0.91920000000000002), (0.31036978609397559, 0.91449999999999998), (0.318354331305436, 0.90449999999999997), (0.29831928891037235, 0.91110000000000002), (0.29047910043313879, 0.91820000000000002), (0.29148025968604413, 0.91500000000000004), (0.27035655181512891, 0.92589999999999995), (0.26774179750055627, 0.92569999999999997), (0.2863644899202441, 0.92300000000000004), (0.28422448405616968, 0.91830000000000001), (0.27650801382157747, 0.92110000000000003), (0.27080538139917504, 0.92500000000000004), (0.28538326908369399, 0.92020000000000002), (0.2640530811081549, 0.92720000000000002)], (0.26513090460045308, 0.92349999999999999))\n"
     ]
    }
   ],
   "source": [
    "shelve_r = shelve.open(\"augExperiments\")\n",
    "\n",
    "print shelve_r['allAug0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All with improved rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.773. Accuracy is 9.29%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.763. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 1.203. Accuracy is 79.53%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.547. Accuracy is 90.61%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 121 seconds. Training speed 419 pps. Validation speed 4639 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.627. Accuracy is 88.18%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.459. Accuracy is 93.66%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 121 seconds. Training speed 420 pps. Validation speed 4502 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.538. Accuracy is 91.01%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.422. Accuracy is 94.68%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 117 seconds. Training speed 434 pps. Validation speed 4697 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.480. Accuracy is 92.82%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.386. Accuracy is 95.86%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 118 seconds. Training speed 432 pps. Validation speed 4727 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.439. Accuracy is 94.08%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.371. Accuracy is 96.07%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 120 seconds. Training speed 423 pps. Validation speed 4222 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.415. Accuracy is 94.84%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.359. Accuracy is 96.62%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 120 seconds. Training speed 425 pps. Validation speed 4885 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.397. Accuracy is 95.42%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.346. Accuracy is 97.03%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 119 seconds. Training speed 429 pps. Validation speed 4866 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.383. Accuracy is 95.92%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.341. Accuracy is 97.08%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 116 seconds. Training speed 437 pps. Validation speed 4842 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.372. Accuracy is 96.20%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.335. Accuracy is 97.27%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 116 seconds. Training speed 440 pps. Validation speed 4839 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.363. Accuracy is 96.58%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.340. Accuracy is 97.32%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 116 seconds. Training speed 439 pps. Validation speed 4853 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.357. Accuracy is 96.74%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.335. Accuracy is 97.37%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 116 seconds. Training speed 439 pps. Validation speed 4782 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.352. Accuracy is 96.97%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.329. Accuracy is 97.73%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 116 seconds. Training speed 439 pps. Validation speed 4831 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.346. Accuracy is 97.21%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.327. Accuracy is 97.68%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 116 seconds. Training speed 439 pps. Validation speed 4859 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.343. Accuracy is 97.32%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.330. Accuracy is 97.75%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 116 seconds. Training speed 439 pps. Validation speed 4868 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.340. Accuracy is 97.48%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.326. Accuracy is 97.90%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 117 seconds. Training speed 437 pps. Validation speed 4827 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.336. Accuracy is 97.64%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.329. Accuracy is 97.72%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 119 seconds. Training speed 428 pps. Validation speed 4901 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.334. Accuracy is 97.73%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.326. Accuracy is 97.91%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 115 seconds. Training speed 443 pps. Validation speed 4894 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.332. Accuracy is 97.81%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.329. Accuracy is 97.89%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 117 seconds. Training speed 434 pps. Validation speed 4743 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.330. Accuracy is 97.97%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.324. Accuracy is 98.02%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 118 seconds. Training speed 430 pps. Validation speed 4916 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.329. Accuracy is 98.05%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.329. Accuracy is 97.93%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 118 seconds. Training speed 432 pps. Validation speed 4903 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.326. Accuracy is 98.13%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.324. Accuracy is 98.22%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 115 seconds. Training speed 443 pps. Validation speed 4891 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.325. Accuracy is 98.20%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.328. Accuracy is 98.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 115 seconds. Training speed 443 pps. Validation speed 4907 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.325. Accuracy is 98.29%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.324. Accuracy is 98.15%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 119 seconds. Training speed 429 pps. Validation speed 4721 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.324. Accuracy is 98.32%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.326. Accuracy is 98.08%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 122 seconds. Training speed 416 pps. Validation speed 4573 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.323. Accuracy is 98.41%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.326. Accuracy is 98.20%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 119 seconds. Training speed 429 pps. Validation speed 4732 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.322. Accuracy is 98.48%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.330. Accuracy is 98.20%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 123 seconds. Training speed 415 pps. Validation speed 4638 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.321. Accuracy is 98.50%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.327. Accuracy is 98.25%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 117 seconds. Training speed 435 pps. Validation speed 4906 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.320. Accuracy is 98.56%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.328. Accuracy is 98.28%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 118 seconds. Training speed 431 pps. Validation speed 4607 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.320. Accuracy is 98.62%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.329. Accuracy is 98.29%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 118 seconds. Training speed 433 pps. Validation speed 4807 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.320. Accuracy is 98.64%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.329. Accuracy is 98.23%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 122 seconds. Training speed 418 pps. Validation speed 4613 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 98.35 %, cost (ce) is 0.053\n",
      "INFO:root:Starting \n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.546. Accuracy is 9.68%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.548. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 1.807. Accuracy is 41.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.715. Accuracy is 83.41%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 111 seconds. Training speed 461 pps. Validation speed 3849 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.798. Accuracy is 80.68%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.552. Accuracy is 88.73%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 109 seconds. Training speed 468 pps. Validation speed 3946 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.636. Accuracy is 86.25%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.448. Accuracy is 92.39%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 107 seconds. Training speed 479 pps. Validation speed 3984 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.550. Accuracy is 89.05%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.424. Accuracy is 92.86%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 106 seconds. Training speed 484 pps. Validation speed 3969 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.484. Accuracy is 91.12%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.412. Accuracy is 93.30%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 106 seconds. Training speed 481 pps. Validation speed 3965 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.441. Accuracy is 92.55%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.364. Accuracy is 95.17%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 106 seconds. Training speed 484 pps. Validation speed 3987 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.406. Accuracy is 93.79%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.361. Accuracy is 94.99%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 108 seconds. Training speed 472 pps. Validation speed 3926 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.382. Accuracy is 94.55%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.332. Accuracy is 96.08%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 110 seconds. Training speed 464 pps. Validation speed 3821 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.366. Accuracy is 95.07%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.319. Accuracy is 96.64%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 110 seconds. Training speed 466 pps. Validation speed 3916 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.349. Accuracy is 95.74%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.310. Accuracy is 97.10%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 107 seconds. Training speed 478 pps. Validation speed 3772 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.341. Accuracy is 96.01%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.323. Accuracy is 96.56%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 109 seconds. Training speed 470 pps. Validation speed 3952 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.332. Accuracy is 96.33%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.307. Accuracy is 97.18%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 106 seconds. Training speed 485 pps. Validation speed 3977 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.324. Accuracy is 96.72%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.311. Accuracy is 97.18%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 108 seconds. Training speed 475 pps. Validation speed 3967 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.319. Accuracy is 96.90%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.321. Accuracy is 96.94%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 110 seconds. Training speed 467 pps. Validation speed 3960 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.313. Accuracy is 97.12%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.301. Accuracy is 97.47%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 114 seconds. Training speed 449 pps. Validation speed 3927 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.309. Accuracy is 97.30%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.303. Accuracy is 97.40%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 112 seconds. Training speed 459 pps. Validation speed 3602 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.305. Accuracy is 97.48%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.300. Accuracy is 97.74%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 114 seconds. Training speed 451 pps. Validation speed 3916 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.301. Accuracy is 97.65%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.297. Accuracy is 97.77%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 112 seconds. Training speed 458 pps. Validation speed 3890 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.298. Accuracy is 97.77%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.297. Accuracy is 97.83%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 113 seconds. Training speed 454 pps. Validation speed 3635 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.295. Accuracy is 97.93%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.302. Accuracy is 97.77%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 111 seconds. Training speed 462 pps. Validation speed 3820 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.293. Accuracy is 98.04%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.297. Accuracy is 98.03%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 112 seconds. Training speed 459 pps. Validation speed 3359 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.291. Accuracy is 98.10%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.306. Accuracy is 97.74%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 112 seconds. Training speed 457 pps. Validation speed 3956 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.289. Accuracy is 98.20%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.297. Accuracy is 97.93%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 118 seconds. Training speed 436 pps. Validation speed 3463 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.288. Accuracy is 98.27%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.323. Accuracy is 97.26%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 112 seconds. Training speed 458 pps. Validation speed 3940 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.285. Accuracy is 98.42%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.300. Accuracy is 97.94%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 107 seconds. Training speed 478 pps. Validation speed 3917 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.286. Accuracy is 98.40%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.299. Accuracy is 98.06%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 110 seconds. Training speed 467 pps. Validation speed 3881 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.284. Accuracy is 98.49%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.300. Accuracy is 98.12%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 113 seconds. Training speed 453 pps. Validation speed 3779 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.282. Accuracy is 98.60%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.308. Accuracy is 97.97%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 114 seconds. Training speed 448 pps. Validation speed 3963 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.375. Accuracy is 97.26%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.306. Accuracy is 97.92%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 111 seconds. Training speed 460 pps. Validation speed 3879 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.287. Accuracy is 98.56%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.299. Accuracy is 98.20%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 111 seconds. Training speed 462 pps. Validation speed 3766 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 98.30 %, cost (ce) is 0.054\n",
      "INFO:root:Saving Data\n"
     ]
    }
   ],
   "source": [
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateExponential, LearningRateFixed, LearningRateList, LearningRateNewBob, DropoutAnnealed\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "import shelve\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "#Set no aug\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=100, max_num_batches=1000, randomize=True, augmentation = 6)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "learning_rate = 0.5;\n",
    "learningList = []\n",
    "decrement = (learning_rate/max_epochs)\n",
    "\n",
    "#Regulariser weights\n",
    "l1_weight = 0.00\n",
    "'''\n",
    "    Picked l2, as l1 can eliminate some points, which we are doing anyway with dropout, whilst l2 will just shrink \n",
    "    once annealing (dropout) gets closer to 1.\n",
    "'''\n",
    "#l2_weight = 0.00005\n",
    "\n",
    "#Build list once so we don't have to rebuild every time.\n",
    "for i in xrange(0,max_epochs):\n",
    "    #In this order so start learning rate is added\n",
    "    learningList.append(learning_rate)\n",
    "    learning_rate -= decrement\n",
    "\n",
    "\n",
    "\n",
    "#Open file to save to\n",
    "shelve_r = shelve.open(\"allAugExperimentsBet\", writeback = True)\n",
    "\n",
    "stats = []\n",
    "rate = 2\n",
    "\n",
    "\n",
    "'''\n",
    "Since we will have a lot more data, make smaller than normal\n",
    "'''\n",
    "dp_scheduler = None\n",
    "\n",
    "\n",
    "#For each number of layers, new model add layers.\n",
    "for layer in xrange(0,2):\n",
    "    #Set here in case we alter it in a layer experiment\n",
    "    learning_rate = 0.5\n",
    "\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "\n",
    "    logger.info(\"Starting \")\n",
    "\n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "\n",
    "    if layer == 0:\n",
    "        odim = 800\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "    if layer == 1:\n",
    "        odim = 300\n",
    "        model.add_layer(Sigmoid(idim=784, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        model.add_layer(Sigmoid(idim=odim, odim=odim, irange=0.2, rng=rng))\n",
    "        \n",
    "    #Add output layer\n",
    "    model.add_layer(Softmax(idim=odim, odim=10, rng=rng))\n",
    "\n",
    "    #Set rate scheduler here\n",
    "    if rate == 1:\n",
    "        lr_scheduler = LearningRateExponential(start_rate=learning_rate, max_epochs=max_epochs, training_size=100)\n",
    "    elif rate == 2:\n",
    "        lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    elif rate == 3:\n",
    "        # define the optimiser, here stochasitc gradient descent\n",
    "        # with fixed learning rate and max_epochs\n",
    "        lr_scheduler = LearningRateNewBob(start_rate=learning_rate, max_epochs=max_epochs,\\\n",
    "                                          min_derror_stop=.05, scale_by=0.05, zero_rate=learning_rate, patience = 10)\n",
    "\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler, \n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "    \n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "\n",
    "    #Append stats for all test\n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n",
    "    #Should save rate to specific dictionairy in pickle\n",
    "    shelve_r['allAug'+str(layer)] = (tr_stats, valid_stats, (tst_cost, tst_accuracy))\n",
    "\n",
    "logger.info('Saving Data')\n",
    "shelve_r.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
